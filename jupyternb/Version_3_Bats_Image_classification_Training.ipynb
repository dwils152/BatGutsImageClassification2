{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading settings from /Users/thomasyohe/isr/BatGutsImageClassification2/jupyternb/.env\n",
            "my_CONTENT_PATH=/Users/thomasyohe/isr/bguts\n",
            "my_TIF_PATH=/Users/thomasyohe/isr/bguts/tiffs\n"
          ]
        }
      ],
      "source": [
        "env_USE_GOOGLE_COLAB = False\n",
        "env_USE_NVIDIA = False\n",
        "env_CONTENT_PATH = \"\"\n",
        "env_TIF_PATH = \"\"\n",
        "env_IMAGE_SHAPE_X = 0\n",
        "env_IMAGE_SHAPE_Y = 0\n",
        "env_MODEL_FILENAME = \"\"\n",
        "env_FULL_MODEL_PATH = \"\"\n",
        "import sys\n",
        "from settings import load_BatGutsSettings, show_python_version\n",
        "S = load_BatGutsSettings()\n",
        "env_TIF_PATH = S.zTifPath\n",
        "env_CONTENT_PATH = S.zContentPath\n",
        "env_MODEL_FILENAME = S.zModelFilename\n",
        "env_FULL_MODEL_PATH = env_CONTENT_PATH + \"/\" + env_MODEL_FILENAME\n",
        "env_USE_GOOGLE_COLAB = S.useGoogleColab\n",
        "env_USE_NVIDIA = S.useNvidia\n",
        "env_IMAGE_SHAPE_X = S.imageShapeX\n",
        "env_IMAGE_SHAPE_Y = S.imageShapeY\n",
        "if len(env_CONTENT_PATH) == 0:\n",
        "    sys.exit(\"Exiting the script because setings were not processed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJYA-F7f-zKO",
        "outputId": "4c3ea790-7fee-4e09-fe68-739312027131"
      },
      "outputs": [],
      "source": [
        "if env_USE_GOOGLE_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow3cUMRy6IFa",
        "outputId": "4212585d-2da8-4a51-cf04-5b08abbe38c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No GPU, using /device:CPU:0.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if len(device_name) > 0:\n",
        "    print(\"Found GPU at: {}\".format(device_name))\n",
        "else:\n",
        "    device_name = \"/device:CPU:0\"\n",
        "    print(\"No GPU, using {}.\".format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-0X8octo_a-z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.17.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tifffile as tiff\n",
        "from pyngrok import ngrok\n",
        "import numpy as np\n",
        "from PIL import Image as im\n",
        "from PIL import  ImageOps\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import itertools\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from tensorflow.python.keras.utils.data_utils import Sequence\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "%matplotlib inline\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eswTdf6iv3T4"
      },
      "outputs": [],
      "source": [
        "def display_tif_image(path):\n",
        "  baseimage = tiff.imread(path)\n",
        "  print ('original image shape',baseimage.shape)\n",
        "  baseimage = np.squeeze(baseimage)\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.imshow(baseimage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "VtrgInAWwDla",
        "outputId": "5b564abd-3d00-4855-c4a4-3366eb77254c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original image shape (8184, 8248, 3)\n"
          ]
        }
      ],
      "source": [
        "zBaseDir = env_TIF_PATH + \"/LS042_Cormura_brevirostris-LY20_10-insect\"\n",
        "zDir = zBaseDir +\"/LS042_Cormura_brevirostris-LY20_10-insect-guts-LY20-10A-AB-08\"\n",
        "full_path = zDir + \"/LS042_Cormura_brevirostris-LY20_10-insect-guts-LY20-10A-AB-08-LY20-10A_ab_08_LS042_Cobr_2021-09-21 15-27-21 (B,Radius8,Smoothing4).tif\"\n",
        "display_tif_image(full_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "Qr9ABqTHuNC5",
        "outputId": "66d4f559-cf32-45dc-ef33-a4a9a9cc0453"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original image shape (5869, 5876, 3)\n"
          ]
        }
      ],
      "source": [
        "zBase = env_TIF_PATH + \"/DRXXX_Brachyphylla_pumila-LY20_13-nectar\"\n",
        "zDir = zBase + \"/DRXXX_Brachyphylla_pumila-LY20_13-nectar-guts-LY20-13A-HE-014\"\n",
        "file_path = zDir + \"/DRXXX_Brachyphylla_pumila-LY20_13-nectar-guts-LY20-13A-HE-014-LY20-13A-014.tif\"\n",
        "display_tif_image(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gm9Mz6hFsv8K"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import cv2\n",
        "# plt.imshow(image)\n",
        "import time\n",
        "import os\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Zqtpf1mazvrY"
      },
      "outputs": [],
      "source": [
        "#Standardizing the image\n",
        "def standardize_image(img_list):\n",
        "  mean_img = np.mean(img_list,axis=0)\n",
        "  std_img = np.std(img_list,axis=0)\n",
        "  img_list = (img_list - mean_img)/std_img\n",
        "  return img_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UMXLt8JJ1Xgm"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This function is part of a machine learning pipeline for image classification.\n",
        "It's designed to load images from a specific category and associate them with labels.\n",
        "The use of one_hot_list suggests it's preparing data for a multi-class classification task.\n",
        "The function can either start with empty lists or append to existing lists, allowing for batch processing. \n",
        "'''\n",
        "def train_imgs(img_list=list(),category=None,one_hot_list=list(),label_list=list()):\n",
        "    if len(img_list)==0 and len(one_hot_list)==0 and len(label_list)==0 :\n",
        "        img_list=[]\n",
        "        label_list=[]\n",
        "    else:\n",
        "        img_list =img_list\n",
        "    for main_path in glob.glob( env_TIF_PATH + \"/images/Bats_mixed_images_RGB_256/\"+ str(category)+\"/\"):\n",
        "        paths=glob.glob(os.path.join(main_path,\"*.jpeg\"))\n",
        "        print('{} Images Count: {}'.format(category,len(paths)))\n",
        "        for image_path in paths:\n",
        "            image = cv2.imread(image_path)\n",
        "            img_list.append(image)\n",
        "            label_list.append(one_hot_list)\n",
        "    return img_list,label_list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1vaHbPqpjjfu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "def train_imgs(img_list=None, category=None, label_list=None):\n",
        "    img_list = img_list or []\n",
        "    label_list = label_list or []\n",
        "    \n",
        "    file_path = os.path.join(env_CONTENT_PATH, \"images\", \"Bats_mixed_images_RGB_256\", str(category))\n",
        "    \n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Warning: Directory not found for category {category}\")\n",
        "        return img_list, label_list\n",
        "    \n",
        "    image_paths = glob.glob(os.path.join(file_path, \"*.jpeg\"))\n",
        "    print(f'{category} Images Count: {len(image_paths)}')\n",
        "    \n",
        "    for image_path in image_paths:\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is not None:\n",
        "            img_list.append(image)\n",
        "            label_list.append(category)\n",
        "        else:\n",
        "            print(f\"Warning: Could not read image {image_path}\")\n",
        "    \n",
        "    return img_list, label_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9a95l6Gx1os",
        "outputId": "de05f3d8-6b4f-4374-ab73-46c5568ce82a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Insects Images Count: 16\n",
            "Plants Images Count: 30\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "insects_list=list()\n",
        "k=[]\n",
        "insects_list,k=train_imgs(insects_list,'Insects',k)\n",
        "\n",
        "plants_list = list()\n",
        "plants_list,k=train_imgs(plants_list,'Plants',k)\n",
        "\n",
        "len(plants_list[0:97])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcJr8Tmx0bp3",
        "outputId": "9100d24d-b68a-4ea2-be86-018778ea333d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Insects Images Count: 16\n",
            "Plants Images Count: 30\n"
          ]
        }
      ],
      "source": [
        "#prepare training data\n",
        "train_imgs_list = list()\n",
        "labels_list =list()\n",
        "# train_imgs_list,labels_list=train_imgs(train_imgs_list,'Blood',labels_list)\n",
        "train_imgs_list,labels_list=train_imgs(train_imgs_list,'Insects',labels_list)\n",
        "\n",
        "train_imgs_list,labels_list=train_imgs(train_imgs_list,'Plants',labels_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZoyzENVcmtwQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2Z28k4yGmvDI"
      },
      "outputs": [],
      "source": [
        "labels_list= LabelEncoder().fit_transform(labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mqYtw3t0m7oD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({1: 30, 0: 16})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "Counter(labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pz4HswiMIIQo"
      },
      "outputs": [],
      "source": [
        "''' \n",
        "The purpose of this function is to shuffle two lists, train_imgs_list and labels_list, in unison. \n",
        "This is a common preprocessing step in machine learning to ensure that the data is randomized, \n",
        "which helps to prevent the model from learning any unintended patterns that might be \n",
        "present in the order of the data.\n",
        "\n",
        "Why Shuffling is Important\n",
        "Prevent Overfitting: Shuffling helps to prevent the model from overfitting to the order of the data.\n",
        "Better Generalization: It ensures that the model generalizes better by learning from a \n",
        "more diverse set of examples in each epoch.\n",
        "Balanced Batches: When training in batches, shuffling helps to ensure that each batch \n",
        "is representative of the entire dataset.\n",
        "\n",
        "''' \n",
        "import random\n",
        "\n",
        "temp = list(zip(train_imgs_list, labels_list)) # The zip function pairs elements from train_imgs_list \n",
        "                                                # and labels_list together into tuples.\n",
        "random.shuffle(temp)\n",
        "train_imgs_list,labels_list = zip(*temp) # The zip(*temp) expression unpacks the shuffled list of tuples back \n",
        "                                          # into two separate lists.\n",
        "train_imgs_list,labels_list = list(train_imgs_list), list(labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf1MI5PX5PNF",
        "outputId": "5b65e60d-17bc-44b9-e37c-04117f527028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The length of the trained images list is 46\n",
            "The length of the labels list is 46\n"
          ]
        }
      ],
      "source": [
        "li = len(train_imgs_list)\n",
        "print(\"The length of the trained images list is \" + str(li) )\n",
        "ll = len(labels_list)\n",
        "print(\"The length of the labels list is \" + str( ll ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "o1V4yu8o5Rv1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\" \\nThe above line calls a function named standardize_image on the normalized array X.\\nWhile we don't see the implementation of standardize_image, it's likely performing image standardization.\\nStandardization typically involves adjusting the values to have a mean of 0 and a standard \\ndeviation of 1 across the dataset.\\n\\n\""
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''' \n",
        "This code is performing two important preprocessing steps on a set of images, likely in preparation for t\n",
        "raining a machine learning model, particularly a neural network. \n",
        "'''\n",
        "X = np.array(train_imgs_list,np.float32)/255.0\n",
        "''' \n",
        "The abpve line converts train_imgs_list (presumably a list of images) into a NumPy array.\n",
        "It specifies the data type as np.float32 for efficient computation.\n",
        "The division by 255.0 normalizes the pixel values to a range of [0, 1].\n",
        "This normalization is common in image processing because pixel values typically \n",
        "range from 0 to 255 in standard image formats.\n",
        "'''\n",
        "X = standardize_image(X)\n",
        "''' \n",
        "The above line calls a function named standardize_image on the normalized array X.\n",
        "While we don't see the implementation of standardize_image, it's likely performing image standardization.\n",
        "Standardization typically involves adjusting the values to have a mean of 0 and a standard \n",
        "deviation of 1 across the dataset.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "esMKJVNTO8SD"
      },
      "outputs": [],
      "source": [
        "''' \n",
        "This cell is performing the task of splitting a dataset into training and validation (or test) sets.\n",
        "'''\n",
        "\n",
        "''' \n",
        "Splitting the data into train and validation set\n",
        "\n",
        "  X: This is the array of feature data (in this case, probably the images).\n",
        "\n",
        "  labels_list: This is the array of labels corresponding to the feature data.\n",
        "\n",
        "  test_size=0.1: This specifies that 10% of the data should be allocated to the test set, and the remaining 90% to the \n",
        "  training set.\n",
        "\n",
        "  random_state=1: This ensures that the split is reproducible. Setting a random state means that every time you \n",
        "  run the code with the same data and the same random state, you will get the same split.\n",
        "\n",
        "   stratify=labels_list: This ensures that the split preserves the proportion of each class in the labels. \n",
        "   This is particularly important for imbalanced datasets to ensure that both the training and test sets have a \n",
        "   similar distribution of classes.\n",
        "'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,x_test,Y_train,y_test = train_test_split(X,labels_list ,test_size=0.1,random_state=1,stratify=labels_list)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zgXBlGVC0gua"
      },
      "outputs": [],
      "source": [
        "''' \n",
        "The make_pairs function is designed to create pairs of samples from a dataset, along with corresponding \n",
        "labels indicating whether the pairs are from the same class or different classes. This is often used in \n",
        "tasks such as training a Siamese network for similarity learning or one-shot learning.\n",
        "\n",
        "Input Parameters\n",
        "x: A list or array of data samples (e.g., images).\n",
        "y: A list or array of labels corresponding to the data samples.\n",
        "\n",
        "In summary, the make_pairs function is useful for creating training data for models that need to learn \n",
        "relationships or similarities between samples, such as Siamese networks. It ensures that the dataset contains both \n",
        "matching and non-matching pairs, which is crucial for training such models effectively.\n",
        "'''\n",
        "def make_pairs(x, y):\n",
        "    num_classes = max(y) + 1\n",
        "    #print(\"num_classes=\" + str(num_classes) + \" x=\" + str(x) + \"y=\" + str(y)) \n",
        "    digit_indices = [np.where(y == i)[0] for i in range(num_classes)]\n",
        "    #print(\"digit_indices=\"+str(digit_indices))\n",
        "    pairs = []\n",
        "    labels = []\n",
        "\n",
        "    for idx1 in range(len(x)):\n",
        "        #print(idx1)\n",
        "        # add a matching example\n",
        "        x1 = x[idx1]\n",
        "        label1 = y[idx1]\n",
        "        #print(\"label1=\"+str(label1))\n",
        "        for i in range(5):\n",
        "          #print(\"digit_indices[label1=\"+str(digit_indices[label1]))\n",
        "          if digit_indices[label1]:  # Check if the list is not empty\n",
        "            idx2 = random.choice(digit_indices[label1])\n",
        "          else:\n",
        "            # Handle the case where the list is empty\n",
        "            #print(f\"No indices available for label {label1}\")\n",
        "            # You might want to skip this iteration or choose a default value\n",
        "            continue\n",
        "          x2 = x[idx2]\n",
        "\n",
        "          pairs += [[x1, x2]]\n",
        "          labels += [1]\n",
        "\n",
        "          # add a non-matching example\n",
        "          label2 = random.randint(0, num_classes - 1)\n",
        "          while label2 == label1:\n",
        "              label2 = random.randint(0, num_classes - 1)\n",
        "\n",
        "          idx2 = random.choice(digit_indices[label2])\n",
        "          x2 = x[idx2]\n",
        "\n",
        "          pairs += [[x1, x2]]\n",
        "          labels += [0]\n",
        "    a = np.array(pairs)\n",
        "    b = np.array(labels).astype(\"float32\")\n",
        "    print(\"make_pairs returning pairs=\" + str(pairs) + \" np.array(pairs)=\" + str(a) + \" np.array(labels).astype(float32)=\"+str(b))\n",
        "    return a, b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LI-2YGTb4_mV"
      },
      "outputs": [],
      "source": [
        "''' \n",
        "converts labels_list into a NumPy array. Let's break down its purpose and implications:\n",
        "\n",
        "Purpose:\n",
        "NumPy arrays offer several advantages over Python lists, especially in the context of machine \n",
        "learning and data processing:\n",
        "a. Efficiency: NumPy arrays are more memory-efficient and faster to process than Python lists, especially for large datasets.\n",
        "b. Vectorization: NumPy allows for vectorized operations, which can significantly speed up computations.\n",
        "c. Compatibility: Many machine learning libraries and functions (like scikit-learn, TensorFlow, etc.) expect \n",
        "   inputs as NumPy arrays.\n",
        "d. Multidimensional Support: NumPy arrays can easily represent multidimensional data, which is common in machine \n",
        "   learning tasks.\n",
        "'''\n",
        "labels_list = np.array(labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb8I24880lgB",
        "outputId": "62962ffa-fe38-4d66-83f6-65de1a8ae900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "make_pairs returning pairs=[] np.array(pairs)=[] np.array(labels).astype(float32)=[]\n",
            "Shape of pairs_train: (0,)\n",
            "Shape of labels_train: (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/fw/j27fkmm12hz_82xl8gd1v3tc0000gn/T/ipykernel_35684/4061704176.py:17: DeprecationWarning: Calling nonzero on 0d arrays is deprecated, as it behaves surprisingly. Use `atleast_1d(cond).nonzero()` if the old behavior was intended. If the context of this warning is of the form `arr[nonzero(cond)]`, just use `arr[cond]`.\n",
            "  digit_indices = [np.where(y == i)[0] for i in range(num_classes)]\n",
            "/var/folders/fw/j27fkmm12hz_82xl8gd1v3tc0000gn/T/ipykernel_35684/4061704176.py:30: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if digit_indices[label1]:  # Check if the list is not empty\n"
          ]
        }
      ],
      "source": [
        "''' \n",
        " make_pairs is probably designed to create pairs of images, which is a common technique used in certain types of \n",
        " machine learning models, particularly in tasks like Siamese networks, Contrastive learning, One-shot learning. Face verification\n",
        "'''\n",
        "pairs_train, labels_train = make_pairs(X_train, Y_train)\n",
        "print(\"Shape of pairs_train:\", pairs_train.shape)\n",
        "print(\"Shape of labels_train:\", labels_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "oXwHb5dpV5ku"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "make_pairs returning pairs=[] np.array(pairs)=[] np.array(labels).astype(float32)=[]\n",
            "Shape of pairval: (0,)\n",
            "Shape of labelval: (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/fw/j27fkmm12hz_82xl8gd1v3tc0000gn/T/ipykernel_35684/4061704176.py:17: DeprecationWarning: Calling nonzero on 0d arrays is deprecated, as it behaves surprisingly. Use `atleast_1d(cond).nonzero()` if the old behavior was intended. If the context of this warning is of the form `arr[nonzero(cond)]`, just use `arr[cond]`.\n",
            "  digit_indices = [np.where(y == i)[0] for i in range(num_classes)]\n",
            "/var/folders/fw/j27fkmm12hz_82xl8gd1v3tc0000gn/T/ipykernel_35684/4061704176.py:30: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if digit_indices[label1]:  # Check if the list is not empty\n"
          ]
        }
      ],
      "source": [
        "pairval, labelval = make_pairs(x_test, y_test)\n",
        "print(\"Shape of pairval:\", pairval.shape)\n",
        "print(\"Shape of labelval:\", labelval.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ucRPh5UfpG02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(46, 256, 256, 3)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KVawA9VI0mdZ"
      },
      "outputs": [],
      "source": [
        "train_image1 = np.array([pair[0] for pair in pairs_train])\n",
        "train_image2 = np.array([pair[1] for pair in pairs_train])\n",
        "#Below is Jaswanth's original code which get index errors\n",
        "\n",
        "#train_image1 = pairs_train[:, 0]  # x_train_1.shape is (60000, 28, 28)\n",
        "#train_image2 = pairs_train[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "qVdu5BSx1tju"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib import rcParams\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jMCMBSzjM4d2"
      },
      "outputs": [],
      "source": [
        "''' \n",
        "creates a convolutional neural network (CNN) model, typically used as one half of a Siamese network. \n",
        "\n",
        "Key Points:\n",
        "This model is designed for feature extraction, typically used in Siamese networks for tasks like \n",
        "similarity learning or face recognition.\n",
        "\n",
        "It uses a series of convolutional layers with decreasing filter sizes (256 -> 128 -> 64) to extract features.\n",
        "\n",
        "Dropout layers are used for regularization to prevent overfitting.\n",
        "\n",
        "The final dense layer creates an embedding of size embeddingDim.\n",
        "\n",
        "The model doesn't include any classification layers, as it's meant to generate feature embeddings.\n",
        "\n",
        "This architecture is suitable for learning a compact representation of input images, which can then be \n",
        "used to compare similarities between different inputs in a Siamese network setup.\n",
        "\n",
        "'''\n",
        "def build_siamese_model(inputShape, embeddingDim=256):\n",
        "\t# specify the inputs for the feature extractor network\n",
        "\tinputs = Input(inputShape) #Defines the input layer with the specified shape.\n",
        "\t\n",
        " \t# define the first set of CONV => RELU => POOL => DROPOUT layers\n",
        "  \t#First Convolutional Block: 256 filters, 2x2 kernel, ReLU activation, Max pooling with 2x2 pool size30% dropout\n",
        "\tx = Conv2D(256, (2, 2), padding=\"same\", activation=\"relu\")(inputs)\n",
        "\tx = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\tx = Dropout(0.3)(x)\n",
        " \n",
        "\t# second set of CONV => RELU => POOL => DROPOUT layers\n",
        "\t#Second Convolutional Block: wotj similar pool and dropout attributes\n",
        "\tx = Conv2D(128, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
        "\tx = MaxPooling2D(pool_size=2)(x)\n",
        "\tx = Dropout(0.3)(x)\n",
        "  \n",
        "  # Third set of CONV => RELU => POOL => DROPOUT layers \n",
        "  # Third Convolutional Block: 64 filters and 40% dropout Reduces spatial dimensions to 1x1\n",
        "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
        "\tx = MaxPooling2D(pool_size=2)(x)\n",
        "\tx = Dropout(0.4)(x)\n",
        "  \n",
        "  # prepare the final outputs\n",
        "\tpooledOutput = GlobalAveragePooling2D()(x)\n",
        "\toutputs = Dense(embeddingDim)(pooledOutput)\n",
        "\n",
        "\t# build the model\n",
        "\tmodel = Model(inputs, outputs) #Creates a Keras Model with the defined inputs and outputs\n",
        "\n",
        "\t# return the model to the calling function\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "udvHxGPNNMP_"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "calculates the Euclidean distance between pairs of vectors. It's commonly used in Siamese networks to measure \n",
        "the similarity (or dissimilarity) between two input samples. \n",
        "'''\n",
        "def euclidean_distance(vectors):\n",
        "\t# unpack the vectors into separate lists\n",
        "\t(featsA, featsB) = vectors\n",
        "\t# compute the sum of squared distances between the vectors\n",
        "\tsumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
        "\t\tkeepdims=True)\n",
        "\t# return the euclidean distance between the vectors\n",
        "\treturn K.sqrt(K.maximum(sumSquared, K.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "xhkJx-LfNQSa"
      },
      "outputs": [],
      "source": [
        "def plot_training(H, plotPath):\n",
        "\t# construct a plot that plots and saves the training history\n",
        "\tplt.style.use(\"ggplot\")\n",
        "\tplt.figure()\n",
        "\tplt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
        "\tplt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
        "\tplt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
        "\tplt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "\tplt.title(\"Training Loss and Accuracy\")\n",
        "\tplt.xlabel(\"Epoch #\")\n",
        "\tplt.ylabel(\"Loss/Accuracy\")\n",
        "\tplt.legend(loc=\"lower left\")\n",
        "\tplt.savefig(plotPath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7Y7S-D4NUXl",
        "outputId": "74b932c9-a3b7-423a-b350-a63e6789cc35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] building siamese network...\n"
          ]
        }
      ],
      "source": [
        "print(\"[INFO] building siamese network...\")\n",
        "imgA = Input(shape=(256,256,3))\n",
        "imgB = Input(shape=(256,256,3))\n",
        "featureExtractor = build_siamese_model((256,256,3))\n",
        "featsA = featureExtractor(imgA)\n",
        "featsB = featureExtractor(imgB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Cm7lMhiIOUgB"
      },
      "outputs": [],
      "source": [
        "# finally, construct the siamese network\n",
        "distance = Lambda(euclidean_distance)([featsA, featsB])\n",
        "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
        "model = Model(inputs=[imgA, imgB], outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "89to4UAEl2lo"
      },
      "outputs": [],
      "source": [
        "# Defining callback Methods\n",
        "n_epoch = 300\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1,\n",
        "                           mode='auto', restore_best_weights=True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5,\n",
        "                             verbose=1, mode='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXZGgQnKOafC",
        "outputId": "9c37d4c6-2907-4ed8-f31c-a0fd3bcc2e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of pairs_train: (0,)\n",
            "Shape of labels_train: (0,)\n",
            "Shape of pairval: (0,)\n",
            "Shape of labelval: (0,)\n",
            "[INFO] compiling model...\n",
            "[INFO] training model...\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[34], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] training model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m---> 12\u001b[0m \t[pairs_train[:, \u001b[38;5;241m0\u001b[39m], pairs_train[:, \u001b[38;5;241m1\u001b[39m]], labels_train[:],\n\u001b[1;32m     13\u001b[0m \tvalidation_data\u001b[38;5;241m=\u001b[39m([pairval[:, \u001b[38;5;241m0\u001b[39m], pairval[:, \u001b[38;5;241m1\u001b[39m]], labelval[:]),\n\u001b[1;32m     14\u001b[0m \tbatch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, epochs\u001b[38;5;241m=\u001b[39mn_epoch,\n\u001b[1;32m     15\u001b[0m                     callbacks\u001b[38;5;241m=\u001b[39m[reduce_lr,early_stop]\n\u001b[1;32m     16\u001b[0m )\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
          ]
        }
      ],
      "source": [
        "# compile the model\n",
        "# Check the shapes of the arrays\n",
        "print(\"Shape of pairs_train:\", pairs_train.shape)\n",
        "print(\"Shape of labels_train:\", labels_train.shape)\n",
        "print(\"Shape of pairval:\", pairval.shape)\n",
        "print(\"Shape of labelval:\", labelval.shape)\n",
        "\n",
        "# Ensure pairs_train and pairval are 2-dimensional\n",
        "if len(pairs_train.shape) == 1:\n",
        "    pairs_train = pairs_train.reshape(-1, 2)\n",
        "if len(pairval.shape) == 1:\n",
        "    pairval = pairval.reshape(-1, 2)\n",
        "\n",
        "# Check the shapes again after reshaping\n",
        "print(\"Shape of pairs_train after reshaping:\", pairs_train.shape)\n",
        "print(\"Shape of pairval after reshaping:\", pairval.shape)\n",
        "\n",
        "# Compile the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "print(\"[INFO] training model...\")\n",
        "history = model.fit(\n",
        "    [pairs_train[:, 0], pairs_train[:, 1]], labels_train[:],\n",
        "    validation_data=([pairval[:, 0], pairval[:, 1]], labelval[:]),\n",
        "    batch_size=10, epochs=n_epoch,\n",
        "    callbacks=[reduce_lr, early_stop]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "RwXwtH4CXf5l",
        "outputId": "5d9ecf01-0fe2-4ab3-edd6-7d5d1b8376ea"
      },
      "outputs": [],
      "source": [
        "# serialize the model to disk\n",
        "print(\"[INFO] saving siamese model...\")\n",
        "model.save( env_FULL_MODEL_PATH )\n",
        "# plot the training history\n",
        "print(\"[INFO] plotting training history...\")\n",
        "plot_training(history, 'plot.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDX9EkLBGLB2"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "print(\"[INFO] loading siamese model...\")\n",
        "model_path = env_FULL_MODEL_PATH\n",
        "model = load_model(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vechO2ajhB_W",
        "outputId": "67f4bf9f-12af-482f-f82a-75db7f90bf1b"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2hbnzfBhU30"
      },
      "outputs": [],
      "source": [
        "file_base = env_CONTENT_PATH + \"/images/Bats_mixed_images_RGB_256/Plants\"\n",
        "file_path = file_base + \"/DRXXX_Brachyphylla_pumila-LY20_13-nectar-guts-LY20-13A-HE-006-Plane004__blue.jpeg\"\n",
        "imageA = cv2.imread(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ykyYV7_hVxJ",
        "outputId": "8cefd6f2-212e-45a3-e533-c433c44740f8"
      },
      "outputs": [],
      "source": [
        "imageA.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wl5iyBz6Kx1G"
      },
      "outputs": [],
      "source": [
        "category = 'Plants'\n",
        "file_prefix = env_CONTENT_PATH + \"/images/\"\n",
        "for main_path in glob.glob( file_prefix + \"Bats_mixed_images_RGB_256/\"+ str(category)+\"/\"):\n",
        "      paths=glob.glob(os.path.join(main_path,\"*.jpeg\"))\n",
        "print('{} Images Count: {}'.format(category,len(paths)))\n",
        "\n",
        "for i,image_path in enumerate(paths):\n",
        "    imageA = cv2.imread(image_path)\n",
        "    file_path = env_CONTENT_PATH + \"/images/Bats_mixed_images_RGB_256/Plants/DRXXX_Brachyphylla_pumila-LY20_13-nectar-guts-LY20-13A-HE-006-Plane004__blue.jpeg\"\n",
        "    imageB = cv2.imread(file_path)\n",
        "    # create a copy of both the images for visualization purpose\n",
        "    origA = imageA.copy()\n",
        "    origB = imageB.copy()\n",
        "    imageA = np.expand_dims(imageA, axis=-1)\n",
        "    imageB = np.expand_dims(imageB, axis=-1)\n",
        "    # add a batch dimension to both images\n",
        "    imageA = np.expand_dims(imageA, axis=0)\n",
        "    imageB = np.expand_dims(imageB, axis=0)\n",
        "    # scale the pixel values to the range of [0, 1]\n",
        "    imageA = imageA / 255.0\n",
        "    imageB = imageB / 255.0\n",
        "    print(imageA.shape)\n",
        "    # use our siamese model to make predictions on the image pair,\n",
        "    # indicating whether or not the images belong to the same class\n",
        "    preds = model.predict([imageA,imageB])\n",
        "    proba = preds[0][0]\n",
        "    fig = plt.figure(\"Pair #{}\".format(i+1), figsize=(4, 2))\n",
        "    plt.suptitle(\"Similarity: {:.2f}\".format(proba))\n",
        "    # show first image\n",
        "    ax = fig.add_subplot(1, 2, 1)\n",
        "    plt.imshow(origA, cmap=plt.cm.gray)\n",
        "    plt.axis(\"off\")\n",
        "    # show the second image\n",
        "    ax = fig.add_subplot(1, 2, 2)\n",
        "    plt.imshow(origB, cmap=plt.cm.gray)\n",
        "    plt.axis(\"off\")\n",
        "    # show the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "esRNDvEPabNT",
        "outputId": "12968cbe-ed49-41e4-8c44-15a4cccb0bf3"
      },
      "outputs": [],
      "source": [
        "# initialize the figure\n",
        "fig = plt.figure(\"Pair #{}\".format(1), figsize=(4, 2))\n",
        "plt.suptitle(\"Similarity: {:.2f}\".format(proba))\n",
        "# show first image\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "plt.imshow(origA, cmap=plt.cm.gray)\n",
        "plt.axis(\"off\")\n",
        "# show the second image\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "plt.imshow(origB, cmap=plt.cm.gray)\n",
        "plt.axis(\"off\")\n",
        "# show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7v15zlxlrGZ"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8O5XxCxwlqc",
        "outputId": "d1877db3-a781-4376-9c4f-f9c18e1893e2"
      },
      "outputs": [],
      "source": [
        "X.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX8PQM4epqjU"
      },
      "outputs": [],
      "source": [
        "X_re = X.reshape((X.shape[0],256*256*3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixqZI16GwU0P"
      },
      "outputs": [],
      "source": [
        "sm = SMOTE(random_state=42)\n",
        "Xs_train, ys_train = sm.fit_resample(X_re, labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWq8eTBEvBHj",
        "outputId": "2a3fd381-680c-4897-8b9d-1adc713f6a36"
      },
      "outputs": [],
      "source": [
        "Xs_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw30EE9OxHP4"
      },
      "outputs": [],
      "source": [
        "Xs_train = Xs_train.reshape(-1,256,256,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4aZ4qqOxSxT",
        "outputId": "48805b1b-5e0c-4dfd-c981-14fd51c7dc96"
      },
      "outputs": [],
      "source": [
        "Xs_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eO_rJa4xBbJ",
        "outputId": "17a0cbb5-c8f5-4508-ab53-dd0712af2029"
      },
      "outputs": [],
      "source": [
        "len(ys_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZER6QtIzq8Es"
      },
      "outputs": [],
      "source": [
        "# Counter(labels_list_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bYvAHaUrQbH"
      },
      "outputs": [],
      "source": [
        "# len(labels_list_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A60w_sOtrFjf"
      },
      "outputs": [],
      "source": [
        "# X_smote.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APYqu3DcrgXt"
      },
      "outputs": [],
      "source": [
        "# Xsmote=X_smote.reshape(X_smote.shape[0],256,256,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bqn8geEOrrRl"
      },
      "outputs": [],
      "source": [
        "# Xsmote.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWwpxrJ9r77u"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "def one_hot_labels(img_list,classes):\n",
        "\n",
        "\n",
        "  label_numeric = {k:v for v,k in enumerate(set(img_list))}\n",
        "  target_values = [label_numeric[k] for k in img_list]\n",
        "  target_values = np.array(target_values)\n",
        "  target_values = to_categorical(target_values,num_classes=num_classes)\n",
        "  return target_values\n",
        "\n",
        "labels_list = one_hot_labels(labels_list,num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_Q8yOpZsB0Y"
      },
      "outputs": [],
      "source": [
        "# labels_list = np.array(labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbAVMZ7WzQVV"
      },
      "outputs": [],
      "source": [
        "# len(labels_list_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDgnneR4BDHd"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into train and validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,x_test,Y_train,y_test = train_test_split(Xs_train,ys_train ,test_size=0.1,random_state=1,stratify=ys_train)\n",
        "x_train,x_valid,y_train,y_valid = train_test_split(X_train,Y_train,test_size=0.1,random_state=1,stratify=Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "AnlUzlhHyDfX",
        "outputId": "91f511d1-52d6-4a8d-e1ad-d3fe32ddfdc5"
      },
      "outputs": [],
      "source": [
        "''' \n",
        "This cell is performing a split of a dataset into training and validation sets. \n",
        "\n",
        "This approach is a form of train-validation split, which is common in machine learning to have a separate \n",
        "set for validating the model's performance during training. The specific choice of 2000 samples for validation \n",
        "is arbitrary and might be \n",
        "adjusted based on the total size of the dataset and the desired proportions for training and validation.\n",
        "'''\n",
        "LIMIT_VAL = 2000\n",
        "X_train2 = []\n",
        "y_train2 = []\n",
        "X_val = Xs_train[:LIMIT_VAL]\n",
        "y_val = ys_train[:LIMIT_VAL].reset_index(drop=True)\n",
        "X_train2 = Xs_train[LIMIT_VAL:]\n",
        "y_train2 = ys_train[LIMIT_VAL:].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UdWp86bi8lE"
      },
      "outputs": [],
      "source": [
        "''' \n",
        "This cell is setting up an ImageDataGenerator from Keras for data augmentation. Data augmentation i\n",
        "s a technique used to artificially expand a dataset by creating modified versions of existing images. \n",
        "This is particularly useful in deep learning for image classification tasks, \n",
        "as it helps to prevent overfitting and improves the model's ability to generalize.\n",
        "'''\n",
        "# Data Augumentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=10, # rotation\n",
        "        width_shift_range=0.2, # horizontal shift\n",
        "        height_shift_range=0.2, # vertical shift\n",
        "        zoom_range=0.2, # zoom\n",
        "        horizontal_flip=True, # horizontal flip\n",
        "        brightness_range=[0.2,1.2],# brightness\n",
        "        fill_mode='nearest')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk586if-idza"
      },
      "outputs": [],
      "source": [
        "''' \n",
        "compute the internal statistics of the dataset X that are needed for some of the data augmentation techniques. \n",
        "However, it's important to note that for most use cases of ImageDataGenerator, especially with the parameters \n",
        "you've set, this line is actually unnecessary and doesn't have any effect. \n",
        "'''\n",
        "train_datagen.fit(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32sdzv6vMsWR",
        "outputId": "0f26f413-0cbe-4c6a-f76d-afade18b372d"
      },
      "outputs": [],
      "source": [
        "#!pip install keras-unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JceIMx-O-NAb",
        "outputId": "672fdd34-287d-497a-dac4-a8c93c71f32c"
      },
      "outputs": [],
      "source": [
        "# base_model = ResNet50(include_top=False,weights='imagenet',input_shape=(256,256,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-moEnsnM1lf",
        "outputId": "64488093-ccc6-48f4-c64f-8ac79dd8c0dd"
      },
      "outputs": [],
      "source": [
        "''' \n",
        "This cell is importing and creating an instance of a U-Net model, specifically a \n",
        "vanilla U-Net, using the keras_unet library. \n",
        "\n",
        "U-Net Model Overview\n",
        "The U-Net architecture is widely used for image segmentation tasks. It consists of two main parts:\n",
        "Contracting Path (Encoder):\n",
        "This part of the network captures context and features from the input image.\n",
        "It typically consists of a series of convolutional layers followed by max-pooling layers, \n",
        "which progressively reduce the spatial dimensions and increase the depth of the feature maps.\n",
        "Expanding Path (Decoder):\n",
        "This part of the network reconstructs the spatial dimensions of the image while combining the high-level \n",
        "features captured by the encoder.\n",
        "It typically consists of upsampling layers (like transposed convolutions) and concatenation with \n",
        "corresponding feature maps from the encoder (skip connections).\n",
        "\n",
        "\n",
        "'''\n",
        "from keras_unet.models import vanilla_unet\n",
        "\n",
        "base_model  = vanilla_unet(input_shape=(256, 256, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORBtwbwt_3oQ",
        "outputId": "d2d07cea-073e-460d-b3af-5d553a5c95b4"
      },
      "outputs": [],
      "source": [
        "''' \n",
        "This code is creating a new model by adding additional layers on top of a pre-existing base model \n",
        "(likely the U-Net model you created earlier). \n",
        "\n",
        "What this code accomplishes:\n",
        "Transfer Learning: It's using the base model (likely the U-Net) as a feature extractor.\n",
        "Classification Head: It's adding a classification head on top of the base model, turning what was \n",
        " likely a segmentation model into a classification model.\n",
        "Binary Classification: The final layer with 2 units and softmax activation suggests this is \n",
        "  now set up for binary classification.\n",
        "Regularization: Dropout layers are added to prevent overfitting.\n",
        "Model Composition: It demonstrates how to combine a pre-trained model with additional custom layers.\n",
        "'''\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "add_model = Sequential()\n",
        "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "add_model.add(Dense(256,activation='relu'))\n",
        "add_model.add(Dropout(0.3))\n",
        "add_model.add(Dense(256,activation='relu'))\n",
        "add_model.add(Dropout(0.5))\n",
        "add_model.add(Dense(2,activation='softmax'))\n",
        "model = Model(inputs=base_model.input,outputs = add_model(base_model.output))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjmYFCtkAF2z",
        "outputId": "042039f8-0e2b-4774-9d48-4b474f89fa44"
      },
      "outputs": [],
      "source": [
        "# Compiling Model\n",
        "optimizer = Adam(learning_rate=1e-5)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GE9D6ZuFAMSn"
      },
      "outputs": [],
      "source": [
        "# Defining callback Methods\n",
        "n_epoch = 60\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1,\n",
        "                           mode='auto', restore_best_weights=True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5,\n",
        "                             verbose=1, mode='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-Is5LMxtKnX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pHcl0kQ7Ayi3",
        "outputId": "9569a893-15a1-424e-8d7d-98dc6ef71a6f"
      },
      "outputs": [],
      "source": [
        "for idx, batch_size in enumerate([8, 16,32,64,128]):\n",
        "    history = model.fit(train_datagen.flow(x_train,y_train,batch_size=10),\n",
        "                    epochs=n_epoch,\n",
        "                    callbacks=[reduce_lr,early_stop],\n",
        "                    validation_data=(x_valid,y_valid),steps_per_epoch=batch_size\n",
        "                   )\n",
        "    # Plotting the results on Graph\n",
        "    fig, ax = plt.subplots(2,1)\n",
        "    ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "    ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
        "    legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "    ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "    ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "    legend = ax[1].legend(loc='best', shadow=True)\n",
        "\n",
        "    predictions_model = model.predict(x_test)\n",
        "    predictions_model_max = np.argmax(predictions_model,axis=1)\n",
        "    predictions_onehot = to_categorical(predictions_model_max)\n",
        "    accuracy = accuracy_score(y_test,predictions_onehot)\n",
        "\n",
        "    print(classification_report(y_test,predictions_onehot,target_names=['Insects','Plants']))\n",
        "\n",
        "    # Start MLflow\n",
        "    RUN_NAME = f\"run_{idx}\"\n",
        "    with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name=RUN_NAME) as run:\n",
        "        # Retrieve run id\n",
        "        RUN_ID = run.info.run_id\n",
        "\n",
        "        # Track parameters\n",
        "        mlflow.log_param(\"batch_size\", batch_size)\n",
        "        mlflow.log_param(\"epochs\", 60)\n",
        "        mlflow.log_param(\"image_size\", 256)\n",
        "\n",
        "\n",
        "        # Track model\n",
        "        mlflow.sklearn.log_model(model, \"Bat_guts_IVP_classifier\")\n",
        "\n",
        "        #Track confusion matrix results\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "        mlflow.log_metric('Weighted Precision',(precision_score(y_test,predictions_onehot, average='weighted')))\n",
        "        mlflow.log_metric('Weighted Recall',(recall_score(y_test,predictions_onehot, average='weighted')))\n",
        "        mlflow.log_metric('Weighted F1-score',(f1_score(y_test,predictions_onehot, average='weighted')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a82vFUsF5Epd",
        "outputId": "4a6f6052-8abe-49ad-f981-d2be48b056f8"
      },
      "outputs": [],
      "source": [
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"2AVGMje37gfu1yzYm2UJWam40Mm_dmYa8aw82QJvUCwSCETo\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(port=\"5000\", proto=\"http\", options={\"bind_tls\": True})\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAEPMUE1GpS-",
        "outputId": "ebe55026-41f8-42c0-8ac6-bcf5bd43bf2a"
      },
      "outputs": [],
      "source": [
        "!mlflow ui --backend-store-uri /content/drive/MyDrive/mlruns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYzK8jKsCJSf"
      },
      "outputs": [],
      "source": [
        "# Plotting the results on Graph\n",
        "#fig, ax = plt.subplots(2,1)\n",
        "#ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "#ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
        "#legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "#ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "#ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "#legend = ax[1].legend(loc='best', shadow=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_awM-OizByxZ"
      },
      "outputs": [],
      "source": [
        "# Predictions on testing data created from training data\n",
        "predictions_model = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRhBIcgOCr_F"
      },
      "outputs": [],
      "source": [
        "predictions_model_max = np.argmax(predictions_model,axis=1)\n",
        "predictions_onehot = to_categorical(predictions_model_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjWG11UuF_hH",
        "outputId": "be573ab3-25ca-4304-89ff-631d740f4a03"
      },
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XxDOequEw76",
        "outputId": "6922cd80-66d2-4d85-9e78-61d1f744e8fd"
      },
      "outputs": [],
      "source": [
        "predictions_onehot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpzjsRCfCbH6",
        "outputId": "d543714c-ae8d-40a3-d7ec-01361064744f"
      },
      "outputs": [],
      "source": [
        "# Classification Report\n",
        "print(classification_report(y_test,predictions_onehot,target_names=['Insects','Plants']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-N4JbxcG9FB"
      },
      "outputs": [],
      "source": [
        "from keras.applications.xception import preprocess_input,decode_predictions\n",
        "import keras\n",
        "print(\"keras version=\"+str(keras.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtpZWkXn0KDb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn7KBasX0NgJ"
      },
      "outputs": [],
      "source": [
        "def classify(img_path,model):\n",
        "    img = image.load_img(img_path, target_size=(256, 256))\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    img_batch = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    img_preprocessed = preprocess_input(img_batch)\n",
        "\n",
        "    prediction = model.predict(img_preprocessed)\n",
        "    print(prediction)\n",
        "    prediction_max = [int(i > .5) for i in prediction[0]]\n",
        "\n",
        "    if 1 in prediction_max and sum(prediction_max)==1:\n",
        "      # if prediction_max.index(1) ==0:\n",
        "      #   return 'Bat eats Blood'\n",
        "      if prediction_max.index(1) ==0:\n",
        "        return 'This Bat eat Insects'\n",
        "      if prediction_max.index(1) ==1:\n",
        "        return 'This Bat eat Plants'\n",
        "\n",
        "    else:\n",
        "      return prediction_max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "bizfFMQo5Dmu",
        "outputId": "c28e9364-ee58-4cc0-eeb6-2a5444ff9cb8"
      },
      "outputs": [],
      "source": [
        "\n",
        "logged_model = 'runs:/b78dc243ebf244afa46734d35388620a/Bat_guts_IVP_classifier'\n",
        "\n",
        "# Load model as a PyFuncModel.\n",
        "loaded_model = mlflow.pyfunc.load_model(logged_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XESk4OKb0Kut"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEp8U9y6Yvli"
      },
      "outputs": [],
      "source": [
        "file_path = env_CONTENT_PATH + \"/mlruns/0/271bf38e306e4da48d33b43c21fd79de/artifacts/Bat_guts_IVP_classifier/model.pkl\"\n",
        "loaded_model = pickle.load(open(file_path, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "uz_8EVEl0O14",
        "outputId": "455260a4-bf9a-4ab4-8d76-35542c6b6e53"
      },
      "outputs": [],
      "source": [
        "file_path = env_CONTENT_PATH + \"/images/Bats_mixed_images_RGB_256/Plants/DRXXX_Brachyphylla_pumila-LY20_13-nectar-guts-LY20-13A-HE-006-Plane004__blue.jpeg\"\n",
        "classify(file_path,loaded_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "MNj_VDDZ29OT",
        "outputId": "9a74c720-e917-41b9-8276-d70726f1a4db"
      },
      "outputs": [],
      "source": [
        "file_path = env_CONTENT_PATH + \"/images/Bats_mixed_images_RGB_256/Plants/Y20-14C-003__blue.jpeg\"\n",
        "classify(file_path,loaded_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2Lrbs7c29WX"
      },
      "outputs": [],
      "source": [
        "file_prefix = env_CONTENT_PATH +\"/images/\"\n",
        "paths = glob.glob(os.path.join( file_prefix + \"Bats_mixed_images_RGB_256/\"+ str('Plants')+\"/\",\"*.jpeg\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roFhjGYOZzDa"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "rrQ5ewYKZ0v1",
        "outputId": "de64e7ca-7ea0-4204-c2c1-55ac5bba6dcc"
      },
      "outputs": [],
      "source": [
        "file_path = env_CONTENT_PATH + \"/model.pkl\"\n",
        "loaded_model = pickle.load(open( file_path, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUENsd21Anw-",
        "outputId": "75f695c3-bac8-4d20-ce43-bfbc26c4fe0a"
      },
      "outputs": [],
      "source": [
        "len(paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYNMIU2b2MOG"
      },
      "outputs": [],
      "source": [
        "k=0\n",
        "for path in paths:\n",
        "\n",
        "  if 'Bat eats Insects' == classify(path,loaded_model):\n",
        "    print('here')\n",
        "    k=k+1\n",
        "  else:\n",
        "    print(path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCY8HuzrAlKE",
        "outputId": "91c0da31-2f26-44ed-aaa2-c25b0e3e1af2"
      },
      "outputs": [],
      "source": [
        "k,len(paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwBi2-RzC0xF"
      },
      "outputs": [],
      "source": [
        "j=0\n",
        "for path in paths:\n",
        "\n",
        "  if 'Bat eats Plants' == classify(path,loaded_model):\n",
        "    print('here')\n",
        "    j=j+1\n",
        "  else:\n",
        "    print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWDHw5LYDCo_",
        "outputId": "7537ba20-b44b-4e41-9010-fe8e255d9fc2"
      },
      "outputs": [],
      "source": [
        "j,len(paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGMcEKYB4Dyo"
      },
      "outputs": [],
      "source": [
        "#check versions\n",
        "import flask\n",
        "print( \"flask version=\"+str(flask.__version__))\n",
        "print(\"np version=\"+str(np.__version__))\n",
        "\n",
        "show_python_version()\n",
        "import mlflow\n",
        "print(\"mlflow version=\"+str(mlflow.__version__))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
