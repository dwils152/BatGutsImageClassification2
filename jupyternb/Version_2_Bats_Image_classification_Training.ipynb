{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading settings from /Users/thomasyohe/isr/BatGutsImageClassification2/jupyternb/.env\n",
            "my_CONTENT_PATH=/Users/thomasyohe/isr/bguts\n",
            "my_TIF_PATH=/Users/thomasyohe/isr/bguts/tiffs\n"
          ]
        }
      ],
      "source": [
        "env_USE_GOOGLE_COLAB = False\n",
        "env_USE_NVIDIA = False\n",
        "env_CONTENT_PATH = \"\"\n",
        "env_TIF_PATH = \"\"\n",
        "env_WANT_NGROK = False\n",
        "env_Latest_RUN_ID = 0\n",
        "import sys\n",
        "from settings import load_BatGutsSettings, show_python_version, remove_matching_files, get_most_recent_subdirectory, get_most_recent_numeric_subdirectory\n",
        "S = load_BatGutsSettings()\n",
        "env_TIF_PATH = S.zTifPath\n",
        "env_CONTENT_PATH = S.zContentPath\n",
        "env_USE_GOOGLE_COLAB = S.useGoogleColab\n",
        "env_USE_NVIDIA = S.useNvidia\n",
        "if len(env_CONTENT_PATH) == 0:\n",
        "    sys.exit(\"Exiting the script because setings were not processed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJYA-F7f-zKO",
        "outputId": "66e10f4c-b7c7-4f15-aecb-23355117dd48"
      },
      "outputs": [],
      "source": [
        "if env_USE_GOOGLE_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-0X8octo_a-z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PIL Version=10.2.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tifffile as tiff\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import numpy as np\n",
        "from PIL import Image as im\n",
        "from PIL import  ImageOps\n",
        "print( \"PIL Version=\"+str(im.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i65tutFuuzYS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version=2.16.1\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries for deep learning and data manipulation\n",
        "\n",
        "import numpy as np  # Library for numerical operations\n",
        "import tensorflow as tf  # Library for building machine learning models\n",
        "from tensorflow import keras  # High-level API for Keras functionality\n",
        "from tensorflow.keras.models import Sequential  # Type of neural network model\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout  # Various layers for building models\n",
        "\n",
        "# Import libraries for training and optimizing models\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam  # Optimization algorithm for training\n",
        "from tensorflow.keras.metrics import categorical_crossentropy  # Metric for evaluating multi-class classification\n",
        "\n",
        "# Import libraries for data augmentation and preprocessing\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Library for image augmentation\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50  # Pre-trained model for image classification\n",
        "\n",
        "# Import libraries for saving and loading models, callbacks, and metrics\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau  # Callbacks for model optimization\n",
        "from tensorflow.keras.models import Model  # Type of neural network model\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report  # Metrics for evaluating model performance\n",
        "from tensorflow.keras.utils import to_categorical  # Function for converting labels to categorical format\n",
        "\n",
        "# Import libraries for file manipulation and plotting\n",
        "\n",
        "import itertools  # Library for combinatorial algorithms\n",
        "import os  # Library for interacting with the operating system\n",
        "import shutil  # Library for copying and moving files\n",
        "import random  # Library for generating random numbers\n",
        "import glob  # Library for finding files based on patterns\n",
        "import matplotlib.pyplot as plt  # Library for creating static, animated, and interactive visualizations\n",
        "import warnings\n",
        "from tensorflow.python.keras.utils.data_utils import Sequence\n",
        "\n",
        "# Suppress future warnings from TensorFlow\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Display the version of TensorFlow being used\n",
        "print(\"Tensorflow version=\" + str(tf.__version__))\n",
        "\n",
        "# Enable inline plotting with Matplotlib\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8TIko_KUnm54"
      },
      "outputs": [],
      "source": [
        "import mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Fitsuug-4HsS"
      },
      "outputs": [],
      "source": [
        "zUrl = env_CONTENT_PATH + \"/mlruns/\"\n",
        "mlflow.set_tracking_uri(zUrl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AeYlNmnRJkeq"
      },
      "outputs": [],
      "source": [
        "zPath = env_CONTENT_PATH + \"/mlruns\"\n",
        "remove_matching_files( zPath, \"*\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y3CRZbE_ntV9"
      },
      "outputs": [
        {
          "ename": "MlflowException",
          "evalue": "Experiment 'Batguts-Insects_vs_plants_Unet_256' already exists.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m EXPERIMENT_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatguts-Insects_vs_plants_Unet_256\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m EXPERIMENT_ID \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mcreate_experiment(EXPERIMENT_NAME)\n",
            "File \u001b[0;32m/opt/miniconda3/envs/batGuts/lib/python3.11/site-packages/mlflow/tracking/fluent.py:1725\u001b[0m, in \u001b[0;36mcreate_experiment\u001b[0;34m(name, artifact_location, tags)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_experiment\u001b[39m(\n\u001b[1;32m   1678\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     artifact_location: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1680\u001b[0m     tags: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1681\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;124;03m    Create an experiment.\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;124;03m        Creation timestamp: 1662004217511\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MlflowClient()\u001b[38;5;241m.\u001b[39mcreate_experiment(name, artifact_location, tags)\n",
            "File \u001b[0;32m/opt/miniconda3/envs/batGuts/lib/python3.11/site-packages/mlflow/tracking/client.py:1295\u001b[0m, in \u001b[0;36mMlflowClient.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_experiment\u001b[39m(\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1245\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   1246\u001b[0m     artifact_location: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1247\u001b[0m     tags: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1248\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \n\u001b[1;32m   1251\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \n\u001b[1;32m   1294\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tracking_client\u001b[38;5;241m.\u001b[39mcreate_experiment(name, artifact_location, tags)\n",
            "File \u001b[0;32m/opt/miniconda3/envs/batGuts/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:499\u001b[0m, in \u001b[0;36mTrackingServiceClient.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    496\u001b[0m \n\u001b[1;32m    497\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    498\u001b[0m _validate_experiment_artifact_location(artifact_location)\n\u001b[0;32m--> 499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mcreate_experiment(\n\u001b[1;32m    500\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    501\u001b[0m     artifact_location\u001b[38;5;241m=\u001b[39martifact_location,\n\u001b[1;32m    502\u001b[0m     tags\u001b[38;5;241m=\u001b[39m[ExperimentTag(key, value) \u001b[38;5;28;01mfor\u001b[39;00m (key, value) \u001b[38;5;129;01min\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mitems()] \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;28;01melse\u001b[39;00m [],\n\u001b[1;32m    503\u001b[0m )\n",
            "File \u001b[0;32m/opt/miniconda3/envs/batGuts/lib/python3.11/site-packages/mlflow/store/tracking/file_store.py:394\u001b[0m, in \u001b[0;36mFileStore.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_root_dir()\n\u001b[1;32m    393\u001b[0m _validate_experiment_name(name)\n\u001b[0;32m--> 394\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_experiment_does_not_exist(name)\n\u001b[1;32m    395\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m _generate_unique_integer_id()\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_experiment_with_id(name, \u001b[38;5;28mstr\u001b[39m(experiment_id), artifact_location, tags)\n",
            "File \u001b[0;32m/opt/miniconda3/envs/batGuts/lib/python3.11/site-packages/mlflow/store/tracking/file_store.py:386\u001b[0m, in \u001b[0;36mFileStore._validate_experiment_does_not_exist\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperiment \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists in deleted state. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can restore the experiment, or permanently delete the experiment \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    383\u001b[0m         databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_ALREADY_EXISTS,\n\u001b[1;32m    384\u001b[0m     )\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperiment \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    388\u001b[0m         databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_ALREADY_EXISTS,\n\u001b[1;32m    389\u001b[0m     )\n",
            "\u001b[0;31mMlflowException\u001b[0m: Experiment 'Batguts-Insects_vs_plants_Unet_256' already exists."
          ]
        }
      ],
      "source": [
        "EXPERIMENT_NAME = \"Batguts-Insects_vs_plants_Unet_256\"\n",
        "EXPERIMENT_ID = mlflow.create_experiment(EXPERIMENT_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eswTdf6iv3T4"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This code defines a simple function called `display_image` that displays an image from its original file path.\n",
        "The function takes one argument, `path`, which is expected to be the file path of the TIFF image to be displayed.\n",
        "Within the function, it uses the `tiff.imread()` function (from the `tifffile` library) to read the image data \n",
        "from the specified file path and stores it in a variable called `baseimage`.\n",
        "The original shape of the image is then printed out for reference purposes.\n",
        "Next, any unnecessary dimensions are removed from the image data using `np.squeeze()`, which helps simplify plotting.\n",
        "Finally, a new figure is created for displaying the image using `plt.figure()`, \n",
        "and the image itself is displayed within this figure using `plt.imshow()`.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Define a function to display an image at its original path.\n",
        "\n",
        "def display_image(path):\n",
        "    \"\"\"\n",
        "    This function displays an image from the given path.\n",
        "\n",
        "    Args:\n",
        "        path (str): The file path of the image to be displayed.\n",
        "    \"\"\"\n",
        "\n",
        "    # Read the TIFF image from the specified path using tiff.imread\n",
        "\n",
        "    baseimage = tiff.imread(path)\n",
        "\n",
        "    # Print the original shape of the image for reference\n",
        "\n",
        "    print('Original image shape:', baseimage.shape)\n",
        "\n",
        "    # Remove any unnecessary dimensions (i.e., squeeze) to make plotting easier\n",
        "\n",
        "    baseimage = np.squeeze(baseimage)\n",
        "\n",
        "    # Create a new figure in which to display the image using plt.figure()\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    # Display the image within the newly created figure using plt.imshow()\n",
        "    \n",
        "    plt.imshow(baseimage)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "VtrgInAWwDla",
        "outputId": "7ffcad35-11e4-4a54-cf63-07f4fb45717a"
      },
      "outputs": [],
      "source": [
        "zBase = env_TIF_PATH + \"/LS042_Cormura_brevirostris-LY20_10-insect\"\n",
        "zDir = zBase + \"/LS042_Cormura_brevirostris-LY20_10-insect-guts-LY20-10A-AB-08\"\n",
        "zFile = zDir + \"/LS042_Cormura_brevirostris-LY20_10-insect-guts-LY20-10A-AB-08-Plane000.tif\"\n",
        "display_image(zFile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "Qr9ABqTHuNC5",
        "outputId": "171eacd0-ba54-4162-ef04-db33de117ee1"
      },
      "outputs": [],
      "source": [
        "zBase = env_TIF_PATH + \"/DRXXX_Brachyphylla_pumila-LY20_13-nectar\"\n",
        "zDir = zBase + \"/DRXXX_Brachyphylla_pumila-LY20_13-nectar-guts-LY20-13A-HE-006\"\n",
        "zFile = zDir + \"/DRXXX_Brachyphylla_pumila-LY20_13-nectar-guts-LY20-13A-HE-006-Plane004.tif\"\n",
        "display_image(zFile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gm9Mz6hFsv8K"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Import Seaborn library for creating informative and attractive statistical graphics.\n",
        "Define a function called `standardize_image` that takes in a list of images as input.\n",
        "\"\"\"\n",
        "\n",
        "import seaborn as sns  # 'as' keyword assigns an alias, 'sns', to the library for easy use\n",
        "\n",
        "# Import OpenCV (cv2) library for image and video processing tasks.\n",
        "\n",
        "import cv2  # This library provides a wide range of functionalities for image and video analysis.\n",
        "\n",
        "# Import time library to measure execution times or timestamps in your code.\n",
        "\n",
        "import time  # This library is used to track the passage of time, which can be useful in various scenarios.\n",
        "\n",
        "# Import os (operating system) library to interact with the file system and perform various operations.\n",
        "\n",
        "import os  # This library provides a way to create, delete, and manage directories and files.\n",
        "\n",
        "# Import glob library for finding files based on patterns or globbing.\n",
        "\n",
        "import glob  # This library is used to search for files in directories and subdirectories that match specific criteria.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zqtpf1mazvrY"
      },
      "outputs": [],
      "source": [
        "#Standardizing the image\n",
        "\n",
        "def standardize_image(img_list):\n",
        "  # Calculate the mean image by taking the average of all images along the axis=0 (i.e., feature-wise).\n",
        "  mean_img = np.mean(img_list, axis=0)\n",
        "  \n",
        "  # Calculate the standard deviation of each image by taking the std along the axis=0 (i.e., feature-wise).\n",
        "  std_img = np.std(img_list, axis=0)\n",
        "  \n",
        "  # Subtract the mean from each image and then divide by the standard deviation to standardize the images.\n",
        "  img_list = (img_list - mean_img) / std_img\n",
        "  \n",
        "  # Return the list of standardized images.\n",
        "  return img_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vaHbPqpjjfu"
      },
      "outputs": [],
      "source": [
        "# Define a function to train images based on their categories.\n",
        "\n",
        "   \n",
        "def train_imgs(category):\n",
        "    img_list = []\n",
        "    label_list = []\n",
        "    category_path = os.path.join(env_CONTENT_PATH, \"images/Bats_mixed_images_RGB_256\", str(category))\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Directory does not exist: {category_path}\")\n",
        "        return img_list, label_list\n",
        "    for main_path in glob.glob(category_path + \"/\"):\n",
        "        paths = glob.glob(os.path.join(main_path, \"*.jpeg\"))\n",
        "        print('{} Images Count: {}'.format(category, len(paths)))\n",
        "        for image_path in paths:\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is not None:\n",
        "                img_list.append(image)\n",
        "                label_list.append(category)\n",
        "            else:\n",
        "                print(f\"Failed to read image: {image_path}\")\n",
        "    print(f'{category} images loaded: {len(img_list)}, labels loaded: {len(label_list)}')\n",
        "    return img_list, label_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9a95l6Gx1os",
        "outputId": "a70cb77f-e139-4830-d897-4a6cfc02259d"
      },
      "outputs": [],
      "source": [
        "\n",
        "insects_list, insect_labels = train_imgs('Insects')\n",
        "plants_list, plant_labels = train_imgs('Plants')\n",
        "\n",
        "print(f'Total insects images: {len(insects_list)}, Total plants images: {len(plants_list)}')\n",
        "\n",
        "train_imgs_list = insects_list + plants_list\n",
        "labels_list = insect_labels + plant_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei988CND8NRc",
        "outputId": "cbe6416b-3c60-4193-ad0d-d3d501e72252"
      },
      "outputs": [],
      "source": [
        "len(plants_list[0:97])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcJr8Tmx0bp3",
        "outputId": "cdc80397-0d8c-4c02-a7f9-b98946eaebf8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoyzENVcmtwQ"
      },
      "outputs": [],
      "source": [
        "# Import the LabelEncoder class from scikit-learn's preprocessing module\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "labels_list = label_encoder.fit_transform(labels_list)\n",
        "\n",
        "# Note: The output is not a simple numerical assignment, but rather an array-like object with the transformed labels\n",
        "# Ensure lengths match\n",
        "\n",
        "assert len(train_imgs_list) == len(labels_list), \"The number of images and labels should match\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqYtw3t0m7oD"
      },
      "outputs": [],
      "source": [
        "# Import the Counter class from Python's built-in collections module\n",
        "from collections import Counter\n",
        "\n",
        "# Create a Counter object to count the occurrences of each label in the list\n",
        "counter = Counter(labels_list)\n",
        "\n",
        "# Print or store the resulting Counter object, which contains the frequency of each label\n",
        "print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pz4HswiMIIQo"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "This section of the code shuffles the combined train images and labels into a random order.\n",
        "The goal is to randomize the data so that machine learning models are trained on a diverse set of examples, \n",
        "which can help improve their generalization performance.\n",
        "\"\"\"\n",
        "#Shuffle the data\n",
        "\n",
        "import random\n",
        "\n",
        "temp = list(zip(train_imgs_list, labels_list))\n",
        "random.shuffle(temp)\n",
        "if len(temp) == 0:\n",
        "    print(\"No data to unpack. Check if images are being loaded correctly.\")\n",
        "train_imgs_list, labels_list = zip(*temp)\n",
        "train_imgs_list, labels_list = list(train_imgs_list), list(labels_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf1MI5PX5PNF",
        "outputId": "2066fef7-9c81-4519-f1d8-a7563cc49951"
      },
      "outputs": [],
      "source": [
        "len(train_imgs_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKNSwuBe9H3L",
        "outputId": "a435a25b-0227-459c-8381-19ebb0d5845c"
      },
      "outputs": [],
      "source": [
        "len(labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1V4yu8o5Rv1"
      },
      "outputs": [],
      "source": [
        "# Convert to numpy arrays and preprocess\n",
        "\n",
        "X = np.array(train_imgs_list, np.float32) / 255.0\n",
        "X = standardize_image(X)\n",
        "labels_list = np.array(labels_list)\n",
        "# Ensure lengths match\n",
        "assert X.shape[0] == labels_list.shape[0], \"The number of images and labels should match after preprocessing\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucRPh5UfpG02",
        "outputId": "29558381-cde4-4a70-df50-fd4a18c6288a"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP0J1iEL5j0l",
        "outputId": "d7737863-a5ea-4a3f-eaa4-68ae8fdb64c7"
      },
      "outputs": [],
      "source": [
        "len(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IYseM_HBoHF"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Converting List of Labels to NumPy Array\n",
        "\n",
        "# In many machine learning applications, it's common to work with lists or arrays of labels. \n",
        "# Here's how you can convert a list into a numpy array.\n",
        "\n",
        "# Why Use NumPy Arrays?\n",
        "\n",
        "# NumPy arrays are powerful data structures that can significantly improve performance and efficiency in numerical computations. \n",
        "# By using numpy arrays, you can take advantage of vectorized operations, which can speed up your code by orders of magnitude compared \n",
        "# to using Python lists or other data structures.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "labels_list = np.array(labels_list)\n",
        "\n",
        "# This line of code converts the list of labels into a numpy array.\n",
        "# The resulting array has the same elements as the original list, but with additional capabilities and features provided by numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZER6QtIzq8Es",
        "outputId": "06571805-6d37-486f-815f-210d8d934e42"
      },
      "outputs": [],
      "source": [
        "Counter(labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bYvAHaUrQbH"
      },
      "outputs": [],
      "source": [
        "len(labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A60w_sOtrFjf"
      },
      "outputs": [],
      "source": [
        "# X_smote.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqn8geEOrrRl",
        "outputId": "c3fca01a-a761-421d-96a8-ed69648e0220"
      },
      "outputs": [],
      "source": [
        "# X_smote.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4848J6TxuwT",
        "outputId": "161af694-0ca9-4a66-94a6-b28023e26b6a"
      },
      "outputs": [],
      "source": [
        "np.array(labels_list).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWwpxrJ9r77u"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\"\"\"\n",
        "The function one_hot_labels(img_list, classes) generates one-hot encoded labels from a list of image labels.\n",
        "\n",
        "# Here's how it works:\n",
        "\n",
        "# It creates a dictionary label_numeric where each unique label in img_list \n",
        "# is assigned a unique numeric value. It then replaces the original labels with their corresponding \n",
        "# numeric values using a list comprehension (target_values = [label_numeric[k] for k in img_list]). \n",
        "# The resulting list of numeric labels is converted to an numpy array (target_values = np.array(target_values)). \n",
        "# Finally, it uses the to_categorical() function (which likely comes from the Keras library) \n",
        "# to generate one-hot encoded labels from the numeric labels. \n",
        "# The num_classes=2 argument means that there are only 2 possible classes or categories in the data. \n",
        "# The to_categorical() function will output a numpy array with shape (n_samples, 2), \n",
        "# where each row represents a sample and has two elements: one for class 0 and one for class 1.\n",
        "\"\"\"\n",
        "\n",
        "# This line of code specifies the number of classes or categories that the model will be trained on.\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "def one_hot_labels(img_list,classes):\n",
        "  label_numeric = {k:v for v,k in enumerate(set(img_list))}\n",
        "  target_values = [label_numeric[k] for k in img_list]\n",
        "  target_values = np.array(target_values)\n",
        "  target_values = to_categorical(target_values,num_classes=num_classes)\n",
        "  return target_values\n",
        "\n",
        "labels_list = one_hot_labels(labels_list,num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_G562ZnouGz",
        "outputId": "1ca15560-64e1-4661-c661-7a310ef26aba"
      },
      "outputs": [],
      "source": [
        "labels_list.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_Q8yOpZsB0Y"
      },
      "outputs": [],
      "source": [
        "labels_list = np.array(labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbAVMZ7WzQVV"
      },
      "outputs": [],
      "source": [
        "len(labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDgnneR4BDHd"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into train and validation set\n",
        "\n",
        "# This line of code is using a Python syntax to import a specific function or module. \n",
        "# In this case, it's importing the train_test_split function, which will be used later in the code.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of labels_list:\", labels_list.shape)\n",
        "\n",
        "\"\"\" \n",
        "First Train-Test Split\n",
        "\n",
        "# The next block of code splits the data into training and testing sets.\n",
        "# Here's a breakdown of what this line does:\n",
        "\n",
        "# train_test_split: This is the function being called to split the data.\n",
        "# X_smote and labels_list_smote: These are the input data and labels that need to be split into training and testing sets.\n",
        "# test_size=0.2: This parameter specifies that 20% of the data should be used for testing, while the remaining 90% is used for training.\n",
        "# random_state=1: This parameter ensures that the same random seed is used every time the function is called, which helps with reproducibility.\n",
        "# The result of this line of code is four new variables: X_train, x_test, Y_train, and y_test. \n",
        "# These variables represent the training data (X_train), testing data (x_test), training labels (Y_train), and testing labels (y_test).\n",
        "\"\"\"\n",
        "\n",
        "X_train, x_test, Y_train, y_test = train_test_split(X, labels_list, test_size=0.2, random_state=1, stratify=labels_list) # 20% of the data for validation + test\n",
        "\n",
        "\"\"\"\n",
        "Second Train-Valid Split\n",
        "\n",
        "The final block of code splits the training data into two subsets: one for validation and one for further training.\n",
        "\n",
        "This line of code is similar to the first one, but with a few key differences:\n",
        "\n",
        "X_train and Y_train: These are the input data and labels that need to be split into validation and further training sets.\n",
        "test_size=0.5: This parameter specifies that 50% of the data should be used for validation, \n",
        "while the remaining 50% is used for further training.\n",
        "The variables x_train, x_valid, y_train, and y_valid are created to represent the further training data (x_train), \n",
        "validation data (x_valid), further training labels (y_train), and validation labels (y_valid).\n",
        "\"\"\"\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train, test_size=0.5, random_state=1, stratify=Y_train)  # Split the 20% equally for validation and test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Debugging step to verify the number of images and labels after splitting\n",
        "print(f'Train images: {X_train.shape[0]}, Train labels: {Y_train.shape[0]}')\n",
        "print(f'Validation images: {x_valid.shape[0]}, Validation labels: {y_valid.shape[0]}')\n",
        "print(f'Test images: {x_test.shape[0]}, Test labels: {y_test.shape[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6oM7DPTnqBd",
        "outputId": "c7b19621-c3f3-490d-b1e4-5596e7363732"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TESS4ywnsO3",
        "outputId": "d7b627df-5c77-467f-b685-ec6119cb02bd"
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UdWp86bi8lE"
      },
      "outputs": [],
      "source": [
        "# Printing lengths and shapes\n",
        "lengths_shapes = {\n",
        "    \"Length of train_imgs_list\": len(train_imgs_list),\n",
        "    \"Length of labels_list\": len(labels_list),\n",
        "    \"Shape of X\": X.shape,\n",
        "    \"Shape of labels_list\": labels_list.shape,\n",
        "    \"Shape of x_train\": x_train.shape,\n",
        "    \"Shape of y_train\": y_train.shape,\n",
        "    \"Shape of x_valid\": x_valid.shape,\n",
        "    \"Shape of y_valid\": y_valid.shape,\n",
        "    \"Shape of X_train\": X_train.shape,\n",
        "    \"Shape of Y_train\": Y_train.shape,\n",
        "    \"Shape of x_test\": x_test.shape,\n",
        "    \"Shape of y_test\": y_test.shape\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Displaying lengths and shapes using pandas\n",
        "import pandas as pd\n",
        "lengths_shapes_df = pd.DataFrame(lengths_shapes.items(), columns=['Variable', 'Value'])\n",
        "print(lengths_shapes_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk586if-idza"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Explanation of train_datagen.fit(X)\n",
        "\n",
        "Overview\n",
        "The provided code snippet involves using a Keras data generator, specifically a DataGenerator object named train_datagen, to fit the training data. \n",
        "The main function being called is fit(), which is used to initialize and configure the data generator for training.\n",
        "\n",
        "Step 1: Understanding the fit() Method\n",
        "The fit() method is a common interface in Keras that allows you to train a model with a given dataset. \n",
        "In this case, we're using it to fit the training data to the train_datagen object.\n",
        "\n",
        "Here's what's happening:\n",
        "\n",
        "train_datagen: This is an instance of a Keras DataGenerator, which is used to generate batches of data for training.\n",
        ".fit(): This method is called on the train_datagen object, passing in the training data (X) as input.\n",
        "Step 2: Breaking Down the fit() Method\n",
        "The fit() method takes several parameters that are used to configure the data generator. Some of these parameters include:\n",
        "\n",
        "X: The input training data.\n",
        "y: Not specified here; it's assumed to be provided separately (e.g., in a separate code snippet).\n",
        "epochs: The number of epochs to run during training.\n",
        "verbose: A flag indicating whether to display progress updates during training.\n",
        "validation_data: An optional parameter for providing validation data.\n",
        "In this specific case, we're only passing in the input data (X) without specifying other parameters.\n",
        "This implies that the default values will be used for any unspecified parameters.\n",
        "\n",
        "Step 3: What's Happening Under the Hood\n",
        "When you call fit() on a Keras data generator, several things happen:\n",
        "\n",
        "Data initialization: The data generator is initialized with the provided input data (X).\n",
        "Model configuration: The model architecture and training settings are configured based on the DataGenerator instance.\n",
        "Batch generation: Batches of data are generated from the input data according to the specified batch size.\n",
        "The resulting output will depend on the specific configuration of the data generator, including the number of epochs, batch size, and other parameters.\n",
        "\"\"\"\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=10, # rotation\n",
        "        width_shift_range=0.2, # horizontal shift\n",
        "        height_shift_range=0.2, # vertical shift\n",
        "        zoom_range=0.2, # zoom\n",
        "        horizontal_flip=True, # horizontal flip\n",
        "        brightness_range=[0.2,1.2],# brightness\n",
        "        fill_mode='nearest')\n",
        "\n",
        "train_datagen.fit(X)\n",
        "\n",
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JceIMx-O-NAb",
        "outputId": "672fdd34-287d-497a-dac4-a8c93c71f32c"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Explanation of base_model = ResNet50(include_top=False,weights='imagenet',input_shape=(256,256,3))\n",
        "\n",
        "Overview\n",
        "The provided code snippet involves creating a pre-trained ResNet50 model with specified parameters. This model is used as the base for further training or fine-tuning.\n",
        "\n",
        "Breakdown of Parameters\n",
        "\n",
        "ResNet50: This line creates an instance of the ResNet50 model architecture from Keras.\n",
        "include_top=False: By setting this parameter to False, we're telling the model not to include the \n",
        "top layers (i.e., the classification head) when creating the base model. \n",
        "This is useful for using the pre-trained weights without any additional overhead.\n",
        "weights='imagenet': This parameter specifies that we want to load pre-trained weights from the ImageNet dataset. \n",
        "These weights are trained on a large-scale image classification task and can be used as a starting point for our own tasks.\n",
        "input_shape=(256, 256, 3): This line sets the input shape of the model to images with dimensions 256x256 and 3 color channels (RGB).\n",
        "\n",
        "Step-by-Step Explanation\n",
        "\n",
        "Creating the ResNet50 Model: The first line, ResNet50, creates an instance of the ResNet50 model architecture.\n",
        "Removing Top Layers: By setting include_top=False, we remove the top layers from the model, which typically consist of a classification head and possibly some additional fully connected layers.\n",
        "Loading Pre-Trained Weights: The line weights='imagenet' loads pre-trained weights from the ImageNet dataset into our ResNet50 instance.\n",
        "Specifying Input Shape: Finally, we set the input shape to 256x256 images with 3 color channels (RGB) using the line input_shape=(256, 256, 3).\n",
        "By combining these parameters, we create a pre-trained ResNet50 model without any additional overhead or top layers. This can be used as a starting point for our own image classification tasks.\n",
        "\n",
        "Example Use Case\n",
        "\n",
        "This code snippet is useful when you want to use the benefits of a pre-trained model (such as knowledge distillation) while also having some flexibility in terms of input shapes and architectures. You could then fine-tune this model on your own dataset or use it as a starting point for further training.\n",
        "\n",
        "For example, you might use this code to create a base model for an image classification task.\n",
        "\n",
        "Then, you could add additional layers on top of the base_model to create your own architecture.\n",
        "\"\"\"\n",
        "# base_model = ResNet50(include_top=False,weights='imagenet',input_shape=(256,256,3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-moEnsnM1lf",
        "outputId": "ce056cfd-02dd-40c0-ad59-aed615ed6b8a"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Code Explanation\n",
        "Importing Necessary Libraries\n",
        "The provided code starts with importing a necessary library.\n",
        "\n",
        "from keras_unet.models import vanilla_unet\n",
        "This line imports the vanilla_unet function from the keras_unet.models module.\n",
        "The keras_unet.models module is likely a custom or external library that provides pre-built models for various tasks, including image segmentation and classification.\n",
        "Creating a Base Model\n",
        "The next block of code creates an instance of the vanilla_unet model with a specified input shape.\n",
        "\n",
        "base_model = vanilla_unet(input_shape=(256, 256, 3))\n",
        "This line calls the vanilla_unet function to create a new instance of the model.\n",
        "The input_shape=(256, 256, 3) parameter specifies the expected input shape for this model. In this case, it's expecting images with dimensions 256x256 and 3 color channels (RGB).\n",
        "Step-by-Step Explanation\n",
        "Here's a breakdown of what's happening in the code:\n",
        "\n",
        "Importing the Library: The first line imports the necessary library (keras_unet.models) that provides the vanilla_unet function.\n",
        "Creating an Instance of the Model: The second line calls the vanilla_unet function to create a new instance of the model.\n",
        "Specifying Input Shape: The input_shape=(256, 256, 3) parameter specifies the expected input shape for this model.\n",
        "Purpose and Context\n",
        "The purpose of this code is likely to use the vanilla_unet model as a starting point for further training or fine-tuning on a specific image segmentation task. The input shape specified in the code (256x256 images with 3 color channels) suggests that the model will be used for tasks involving images of similar dimensions.\n",
        "\n",
        "Example Use Cases\n",
        "This code can be useful in various scenarios, such as:\n",
        "\n",
        "Image segmentation: Using the vanilla_unet model as a starting point for fine-tuning on specific image segmentation tasks.\n",
        "Image classification: Adapting the vanilla_unet model to perform image classification tasks by adding additional layers or modifying the architecture.\n",
        "Transfer learning: Using the pre-trained weights of the vanilla_unet model as a starting point for training on a new task.\n",
        "\n",
        "\"\"\"\n",
        "from keras_unet.models import vanilla_unet\n",
        "\n",
        "base_model  = vanilla_unet(input_shape=(256, 256, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1umv6yZ8Vjt"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Code Explanation\n",
        "Importing Necessary Libraries\n",
        "The provided code starts with importing a necessary library.\n",
        "\n",
        "from keras.models import Sequential\n",
        "This line imports the Sequential class from the keras.models module.\n",
        "The keras.models module is part of the Keras deep learning framework, which provides various tools and classes for building neural networks.\n",
        "The Sequential class is a simple way to build neural networks by stacking layers on top of each other.\n",
        "Step-by-Step Explanation\n",
        "Here's a breakdown of what's happening in this line:\n",
        "\n",
        "Importing the Library: This line imports the necessary library (keras.models) that provides the Sequential class.\n",
        "Accessing the Class: By using from keras.models import Sequential, we're accessing the Sequential class directly, so we can use it without having to prefix it with the full module name.\n",
        "Purpose and Context\n",
        "The purpose of this line is to prepare for building a neural network model using the Keras framework. The Sequential class will be used as a base for creating a sequence of layers that can be stacked on top of each other to build a complex neural network architecture.\n",
        "\n",
        "Example Use Cases\n",
        "This code can be useful in various scenarios, such as:\n",
        "\n",
        "Building simple neural networks: Using the Sequential class as a starting point for building simple neural networks.\n",
        "Stacking layers: Creating a sequence of layers using the Sequential class and stacking them on top of each other to build complex neural network architectures.\n",
        "Next Steps\n",
        "\n",
        "Once this line is executed, you can proceed with defining the architecture of your neural network model by adding layers to the Sequential instance. For example:\n",
        "\n",
        "model = Sequential()\n",
        "# Add layers to the model...\n",
        "\n",
        "This will allow you to specify the structure and parameters of your neural network, which can then be trained on your dataset using Keras's training tools.\n",
        "\n",
        "\"\"\"\n",
        "from keras.models import Sequential\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORBtwbwt_3oQ",
        "outputId": "d7f9fb42-8556-4c90-e2e5-a7279de9af2c"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Detailed Explanation of the Provided Code\n",
        "Importing Necessary Libraries\n",
        "The first line imports a necessary library\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "This line imports the BatchNormalization class from the tensorflow.keras.layers module.\n",
        "The BatchNormalization layer is used to normalize the inputs of a neural network, which can help improve the stability and performance of the model.\n",
        "\n",
        "Creating a Sequential Model\n",
        "The next line creates a sequential model:\n",
        "\n",
        "add_model = Sequential()\n",
        "\n",
        "This line creates an instance of the Sequential class, which is a simple way to build neural networks by stacking layers on top of each other.\n",
        "The Sequential model will be used as a building block for the final neural network architecture.\n",
        "Adding Layers to the Model\n",
        "The following lines add layers to the sequential model:\n",
        "\n",
        "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "\n",
        "This line adds a Flatten layer to the model.\n",
        "The Flatten layer is used to flatten the output of a convolutional neural network (CNN) or other layered structure into a 1D array.\n",
        "The input_shape parameter specifies the shape of the input data, which in this case is taken from the output of the base_model.\n",
        "\n",
        "add_model.add(Dense(256,activation='relu'))\n",
        "\n",
        "This line adds a dense (fully connected) layer to the model with 256 neurons and ReLU activation.\n",
        "The Dense layer is used to create a fully connected neural network where each neuron in one layer connects to every neuron in another layer.\n",
        "The activation parameter specifies the activation function to be applied to the output of the layer.\n",
        "\n",
        "add_model.add(Dropout(0.3))\n",
        "\n",
        "This line adds a dropout layer to the model with a dropout rate of 0.3.\n",
        "The Dropout layer is used to randomly drop (or \"drop out\") neurons during training, which can help prevent overfitting and improve the generalization of the model.\n",
        "\n",
        "add_model.add(Dense(256,activation='relu'))\n",
        "\n",
        "This line adds another dense layer with 256 neurons and ReLU activation.\n",
        "The purpose of this second dense layer is to further process and transform the input data before passing it through the final output layer.\n",
        "\n",
        "add_model.add(Dropout(0.2))\n",
        "\n",
        "This line adds a dropout layer with a dropout rate of 0.2.\n",
        "The purpose of this second dropout layer is to help prevent overfitting by randomly dropping neurons during training.\n",
        "\n",
        "add_model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "This line adds a final dense layer with a single output neuron and sigmoid activation.\n",
        "The Dense layer is used to create a fully connected neural network where each neuron in one layer connects to every neuron in another layer.\n",
        "The activation parameter specifies the activation function to be applied to the output of the layer, which in this case is the sigmoid function.\n",
        "\n",
        "Creating the Final Model\n",
        "The next line creates the final model by combining the base model and the additional layers:\n",
        "\n",
        "model = Model(inputs=base_model.input,outputs = add_model(base_model.output))\n",
        "\n",
        "This line creates a new instance of the Model class, which is used to represent the entire neural network architecture.\n",
        "The inputs parameter specifies the input data for the model, which in this case is taken from the input of the base model.\n",
        "The outputs parameter specifies the output data for the model, which in this case is generated by passing the output of the base model through the additional layers.\n",
        "\n",
        "Displaying Model Summary\n",
        "The final line displays a summary of the model:\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "This line calls the summary method on the model instance to display a concise summary of its architecture and parameters.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "add_model = Sequential()\n",
        "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "add_model.add(Dense(256,activation='relu'))\n",
        "add_model.add(Dropout(0.3))\n",
        "add_model.add(Dense(256,activation='relu'))\n",
        "add_model.add(Dropout(0.2))\n",
        "add_model.add(Dense(2,activation='softmax'))\n",
        "model = Model(inputs=base_model.input,outputs = add_model(base_model.output))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_IbOnBl8g5_"
      },
      "outputs": [],
      "source": [
        "# from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fXLfZwCo8qIE",
        "outputId": "0d0bdb4d-1f0c-4215-866f-71e4e3037769"
      },
      "outputs": [],
      "source": [
        "plot_model(model, show_shapes=True, to_file='Vanila_unet_TL.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjmYFCtkAF2z",
        "outputId": "5f68ba69-e923-42a8-844d-52640ad2ba55"
      },
      "outputs": [],
      "source": [
        "# Compiling Model\n",
        "optimizer = Adam(learning_rate=1e-5)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GE9D6ZuFAMSn"
      },
      "outputs": [],
      "source": [
        "# Defining callback Methods\n",
        "\"\"\"\n",
        "Early Stopping and Learning Rate Reduction\n",
        "The provided code snippet is used to implement two important techniques in deep learning: Early Stopping and Learning Rate Reduction.\n",
        "\n",
        "Early Stopping\n",
        "Early stopping is a technique used to prevent overfitting by stopping the training process when the model's performance on a validation set starts to degrade.\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1,\n",
        "                           mode='auto', restore_best_weights=True)\n",
        "\n",
        "EarlyStopping: This is the Keras callback function used for early stopping.\n",
        "monitor='val_loss': The metric that will be monitored. In this case, it's the validation loss.\n",
        "patience=10: The number of epochs to wait before applying early stopping. \n",
        "If the model's performance doesn't improve within this number of epochs, the training process is stopped.\n",
        "verbose=1: This parameter controls the verbosity level of the callback function. \n",
        "A value of 1 means that the callback will print messages during execution.\n",
        "mode='auto': The mode in which to apply early stopping. In this case, it's set to 'auto', \n",
        "which means that the callback will automatically choose the best weights from the previous epochs when the training process is stopped.\n",
        "restore_best_weights=True: If the model's performance doesn't improve within the patience period, \n",
        "this parameter specifies whether to restore the best weights from the previous epoch.\n",
        "\n",
        "Learning Rate Reduction\n",
        "Learning rate reduction is another technique used to prevent overfitting. It involves reducing the learning rate when the model's performance on a validation set starts to degrade.\n",
        "\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5,\n",
        "                             verbose=1, mode='auto')\n",
        "\n",
        "ReduceLROnPlateau: This is the Keras callback function used for learning rate reduction.\n",
        "monitor='val_loss': The metric that will be monitored. In this case, it's the validation loss.\n",
        "factor=0.2: The factor by which to reduce the learning rate when the model's performance on the validation set degrades.\n",
        "patience=5: The number of epochs to wait before reducing the learning rate. \n",
        "If the model's performance doesn't improve within this number of epochs, the learning rate is reduced.\n",
        "verbose=1: This parameter controls the verbosity level of the callback function. A value of 1 means that the callback will print messages during execution.\n",
        "mode='auto': The mode in which to apply learning rate reduction. In this case, it's set to 'auto', \n",
        "which means that the callback will automatically choose the best weights from the previous epochs when the training process is stopped.\n",
        "\n",
        "n_epoch = 60\n",
        "\n",
        "This line sets the number of epochs for which the model will be trained. In this case, it's set to 60. \n",
        "The EarlyStopping and ReduceLROnPlateau callback functions are used in conjunction with this parameter to prevent overfitting during training.\n",
        "\n",
        "Note that the actual number of epochs may vary depending on the specific problem being tackled and the performance metrics used.\n",
        "\n",
        "\"\"\"\n",
        "n_epoch = 60\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1,\n",
        "                           mode='auto', restore_best_weights=True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5,\n",
        "                             verbose=1, mode='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-Is5LMxtKnX"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Detailed Explanation of the Provided Code\n",
        "Importing Necessary Modules\n",
        "The provided code snippet imports necessary modules from scikit-learn:\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "This line imports four metrics from the sklearn.metrics module: accuracy_score, precision_score, recall_score, and f1_score.\n",
        "These metrics are used to evaluate the performance of machine learning models.\n",
        "Understanding the Metrics\n",
        "Let's break down each metric:\n",
        "\n",
        "Accuracy Score\n",
        "The accuracy score is a simple measure of how well a model performs on a given dataset. \n",
        "It calculates the proportion of correctly classified instances out of all instances in the test set.\n",
        "\n",
        "\n",
        "accuracy_score(y_true, y_pred)\n",
        "\n",
        "y_true is the true labels (ground truth) of the data.\n",
        "y_pred is the predicted labels by the model.\n",
        "\n",
        "Precision Score\n",
        "The precision score measures the proportion of correctly classified instances among all positive predictions made by a model. \n",
        "In other words, it tells us how often the model's positive predictions are correct.\n",
        "\n",
        "precision_score(y_true, y_pred)\n",
        "\n",
        "y_true is the true labels (ground truth) of the data.\n",
        "y_pred is the predicted labels by the model.\n",
        "\n",
        "Recall Score\n",
        "The recall score measures the proportion of correctly classified instances among all actual positive instances in the test set. \n",
        "In other words, it tells us how often a model's predictions are correct when they should be positive.\n",
        "\n",
        "\n",
        "recall_score(y_true, y_pred)\n",
        "\n",
        "y_true is the true labels (ground truth) of the data.\n",
        "y_pred is the predicted labels by the model.\n",
        "\n",
        "F1 Score\n",
        "The F1 score is a weighted average of precision and recall. It provides a balanced measure of both precision and recall, \n",
        "with more importance given to accuracy when classifying instances as positive or negative.\n",
        "\n",
        "\n",
        "f1_score(y_true, y_pred)\n",
        "\n",
        "y_true is the true labels (ground truth) of the data.\n",
        "y_pred is the predicted labels by the model.\n",
        "\n",
        "Using These Metrics in Practice\n",
        "\n",
        "These metrics can be used to evaluate the performance of machine learning models on a test set. \n",
        "By calculating these scores, you can get an idea of how well your model performs compared to other models or baseline models.\n",
        "For example, if you're building a classification model for binary classification problems (e.g., spam vs non-spam emails), \n",
        "you might use accuracy score, precision score, and recall score to evaluate the performance. \n",
        "The F1 score would be useful when there's an imbalance in class sizes.\n",
        "Remember that these metrics are not always perfect and should be used in \n",
        "conjunction with other evaluation techniques to get a complete picture of your model's performance.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBRUi2gzpNc9"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Detailed Explanation of the Provided Code\n",
        "Using TensorFlow's Eager Execution Mode\n",
        "The provided code snippet sets up TensorFlow's execution mode to run functions eagerly:\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "This line uses the tf.config API to set the execution mode for TensorFlow.\n",
        "The run_functions_eagerly() function takes a boolean value as input, which determines whether to run functions eagerly or not.\n",
        "\n",
        "What is Eager Execution?\n",
        "In traditional TensorFlow, operations are executed in a graph-based manner. \n",
        "This means that when you create a model and perform computations on it, the operations are recorded in a graph data structure. \n",
        "Then, at some point (e.g., during training), this graph is executed to produce the desired output.\n",
        "However, when using Eager Execution, TensorFlow executes operations immediately as they are created. \n",
        "\n",
        "This provides several benefits:\n",
        "\n",
        "Faster Development: With Eager Execution, you can see the results of your model's computations in real-time, which makes it easier to develop and debug models.\n",
        "Simplified Debugging: Since operations are executed immediately, it's simpler to understand what's happening inside your model.\n",
        "Better Support for Custom Operations: Eager Execution allows TensorFlow to execute custom operations, such as those defined using the tf.function API.\n",
        "\n",
        "Step-by-Step Breakdown\n",
        "Here's how this line of code works:\n",
        "\n",
        "The first part tf.config accesses the configuration module within TensorFlow.\n",
        "The run_functions_eagerly() function is called on this configuration object, which takes a boolean value as input.\n",
        "In this case, the boolean value passed to the function is True, which tells TensorFlow to run functions eagerly.\n",
        "By setting this flag to True, you're telling TensorFlow to execute operations immediately, rather than recording them in a graph for later execution.\n",
        "\n",
        "Note that when running on GPU devices (e.g., NVIDIA GPUs), it's generally recommended to keep the default graph-based mode for performance reasons. \n",
        "However, when developing and debugging models, Eager Execution can be quite useful!\n",
        "\n",
        "\"\"\"\n",
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Printing shapes to verify\n",
        "print(f'x_train shape: {x_train.shape}')\n",
        "print(f'y_train shape: {y_train.shape}')\n",
        "print(f'x_valid shape: {x_valid.shape}')\n",
        "print(f'y_valid shape: {y_valid.shape}')\n",
        "print(f'x_test shape: {x_test.shape}')\n",
        "print(f'y_test shape: {y_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure lengths match\n",
        "assert x_train.shape[0] == y_train.shape[0], \"The number of training images and labels should match\"\n",
        "assert x_valid.shape[0] == y_valid.shape[0], \"The number of validation images and labels should match\"\n",
        "assert x_test.shape[0] == y_test.shape[0], \"The number of test images and labels should match\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pHcl0kQ7Ayi3",
        "outputId": "7673d490-31af-4fb7-efa7-36c387e55e6c"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Detailed Explanation of the Provided Code\n",
        "\n",
        "history = model.fit(train_datagen.flow(x_train, y_train,\n",
        "                                         batch_size=10),\n",
        "                    epochs=n_epoch,\n",
        "                    callbacks=[reduce_lr,early_stop],\n",
        "                    validation_data=(x_valid,y_valid))\n",
        "                    \n",
        "Step 1: Defining the Training Data Generator\n",
        "\n",
        "train_datagen.flow(x_train, y_train, batch_size=10)\n",
        "\n",
        "This line defines a data generator using Keras' flow() method.\n",
        "The first argument x_train is the input data for training.\n",
        "The second argument y_train is the corresponding labels or outputs.\n",
        "The optional third argument batch_size=10 specifies that we want to process 10 samples at a time in batches.\n",
        "The purpose of using a generator here is to avoid loading all the training data into memory at once. \n",
        "This can be particularly useful when working with large datasets, as it allows us to train the model incrementally and more efficiently.\n",
        "\n",
        "Step 2: Defining the Model Fitting Functionality\n",
        "\n",
        "history = model.fit(...)\n",
        "\n",
        "Here we're calling the fit() method on our Keras model instance.\n",
        "The first argument is the training data generator defined in Step 1, \n",
        "which will provide batches of input and output data for each iteration during training.\n",
        "The optional arguments specify various hyperparameters that control how the model trains.\n",
        "\n",
        "Step 3: Specifying Training Epochs\n",
        "\n",
        "epochs=n_epoch,\n",
        "\n",
        "This line specifies the number of epochs (i.e., passes through the entire dataset) to use when training the model. \n",
        "In this case, we're letting it equal n_epoch, which is presumably defined elsewhere in our code.\n",
        "The idea behind epochs is that each iteration will update the weights of the model based on its performance on a small batch of data.\n",
        "\n",
        "Step 4: Defining Callbacks for Early Stopping and Learning Rate Reduction\n",
        "\n",
        "callbacks=[reduce_lr,early_stop],\n",
        "\n",
        "Here we're passing a list of callback functions to the fit() method.\n",
        "These callbacks are used to monitor the training process and take action when certain conditions are met.\n",
        "In this case, we have two callbacks: reduce_lr (learning rate reduction) and early_stop. \n",
        "The first one will reduce the learning rate after each epoch based on a specific schedule. This can help the model converge more smoothly by adjusting its step size adaptively. The second one (early_stop) will stop training when the performance of the model on the validation set doesn't improve for a certain number of epochs (which we'll discuss next).\n",
        "\n",
        "Step 5: Specifying Validation Data\n",
        "\n",
        "validation_data=(x_valid,y_valid)\n",
        "\n",
        "This line specifies the validation data to be used during training. \n",
        "We're passing in x_valid and y_valid, which are presumably defined elsewhere in our code.\n",
        "The idea behind this is that we want to monitor how well the model performs on \n",
        "unseen data (the validation set) as it trains on the entire dataset.\n",
        "The validation data will be passed through the network after each epoch of training, \n",
        "allowing us to assess its performance without affecting its learning process. This can help prevent overfitting and ensure the model generalizes well to new data.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "for idx, batch_size in enumerate([8, 16, 32, 64, 128]):\n",
        "    history = model.fit(train_datagen.flow(x_train, y_train,\n",
        "                                         batch_size=10),\n",
        "                    epochs=n_epoch,\n",
        "                    callbacks=[reduce_lr,early_stop],\n",
        "                    validation_data=(x_valid,y_valid))\n",
        "   \n",
        "    # Plotting the results on Graph\n",
        "\n",
        "    fig, ax = plt.subplots(2,1)\n",
        "    ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "    ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
        "    legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "    ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "    ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "    legend = ax[1].legend(loc='best', shadow=True)\n",
        "\n",
        "    plt.show()  # Ensure the plot displays within each iteration\n",
        "\n",
        "    predictions_model = model.predict(x_test)\n",
        "    predictions_model_max = np.argmax(predictions_model,axis=1)\n",
        "    predictions_onehot = to_categorical(predictions_model_max)\n",
        "    accuracy = accuracy_score(y_test,predictions_onehot)\n",
        "\n",
        "    print(classification_report(y_test,predictions_onehot,target_names=['Insects','Plants']))\n",
        "\n",
        "    # Start MLflow\n",
        "    RUN_NAME = f\"run_{idx}\"\n",
        "    with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name=RUN_NAME) as run:\n",
        "        # Retrieve run id\n",
        "        RUN_ID = run.info.run_id\n",
        "        env_Latest_RUN_ID = RUN_ID\n",
        "        # Track parameters\n",
        "        mlflow.log_param(\"batch_size\", batch_size)\n",
        "        mlflow.log_param(\"epochs\", 60)\n",
        "        mlflow.log_param(\"image_size\", 256)\n",
        "\n",
        "\n",
        "        # Track model\n",
        "        mlflow.sklearn.log_model(model, \"Bat_guts_IVP_classifier\")\n",
        "\n",
        "        #Track confusion matrix results\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "        mlflow.log_metric('Weighted Precision',(precision_score(y_test,predictions_onehot, average='weighted')))\n",
        "        mlflow.log_metric('Weighted Recall',(recall_score(y_test,predictions_onehot, average='weighted')))\n",
        "        mlflow.log_metric('Weighted F1-score',(f1_score(y_test,predictions_onehot, average='weighted')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a82vFUsF5Epd",
        "outputId": "4a6f6052-8abe-49ad-f981-d2be48b056f8"
      },
      "outputs": [],
      "source": [
        "if env_WANT_NGROK:\n",
        "    ngrok.kill()\n",
        "\n",
        "    # Setting the authtoken (optional)\n",
        "    # Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "    NGROK_AUTH_TOKEN = \"2AVGMje37gfu1yzYm2UJWam40Mm_dmYa8aw82QJvUCwSCETo\"\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "    # Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "    ngrok_tunnel = ngrok.connect(port=\"5000\", proto=\"http\", options={\"bind_tls\": True})\n",
        "    print(\"MLflow Tracking UI:\", ngrok_tunnel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAEPMUE1GpS-",
        "outputId": "ebe55026-41f8-42c0-8ac6-bcf5bd43bf2a"
      },
      "outputs": [],
      "source": [
        "# !mlflow ui --backend-store-uri /content/drive/MyDrive/mlruns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYzK8jKsCJSf"
      },
      "outputs": [],
      "source": [
        "# Plotting the results on Graph\n",
        "#fig, ax = plt.subplots(2,1)\n",
        "#ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "#ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
        "#legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "#ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "#ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "#legend = ax[1].legend(loc='best', shadow=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_awM-OizByxZ",
        "outputId": "38424451-54e0-47c1-929d-b4c138ff9468"
      },
      "outputs": [],
      "source": [
        "# Predictions on testing data created from training data\n",
        "predictions_model = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRhBIcgOCr_F"
      },
      "outputs": [],
      "source": [
        "predictions_model_max = np.argmax(predictions_model,axis=1)\n",
        "predictions_onehot = to_categorical(predictions_model_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjWG11UuF_hH",
        "outputId": "d587ab15-22da-4459-f089-b2cd2d0b0335"
      },
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XxDOequEw76",
        "outputId": "d3128efc-8616-4384-e0b4-04c7ab3b1b66"
      },
      "outputs": [],
      "source": [
        "predictions_onehot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpzjsRCfCbH6",
        "outputId": "4781c7e3-6540-4e9d-e6d3-8b0e5c1579cc"
      },
      "outputs": [],
      "source": [
        "# Classification Report\n",
        "print(classification_report(y_test,predictions_onehot,target_names=['Insects','Plants']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-N4JbxcG9FB"
      },
      "outputs": [],
      "source": [
        "from keras.applications.xception import preprocess_input,decode_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfqRF-WML6tS"
      },
      "outputs": [],
      "source": [
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsXRWLm3L0mN",
        "outputId": "54b5f4bf-4edb-44e8-c3af-a4e58e3decf2"
      },
      "outputs": [],
      "source": [
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtpZWkXn0KDb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn7KBasX0NgJ"
      },
      "outputs": [],
      "source": [
        "def classify(img_path,model):\n",
        "    img = image.load_img(img_path, target_size=(256, 256))\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    img_batch = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    img_preprocessed = preprocess_input(img_batch)\n",
        "\n",
        "    prediction = model.predict(img_preprocessed)\n",
        "    print(prediction)\n",
        "    prediction_max = [int(i > .5) for i in prediction[0]]\n",
        "\n",
        "    if 1 in prediction_max and sum(prediction_max)==1:\n",
        "      # if prediction_max.index(1) ==0:\n",
        "      #   return 'Bat eats Blood'\n",
        "      if prediction_max.index(1) ==0:\n",
        "        return 'This Bat eat Insects'\n",
        "      if prediction_max.index(1) ==1:\n",
        "        return 'This Bat eat Plants'\n",
        "\n",
        "    else:\n",
        "      return prediction_max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bizfFMQo5Dmu",
        "outputId": "baab0d79-4f65-4c6e-8205-4b6d706fda63"
      },
      "outputs": [],
      "source": [
        "logged_model = \"runs:/\" + str( env_Latest_RUN_ID) + \"/Bat_guts_IVP_classifier\"\n",
        "# Load model as a PyFuncModel.\n",
        "loaded_model = mlflow.pyfunc.load_model(logged_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XESk4OKb0Kut"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEp8U9y6Yvli"
      },
      "outputs": [],
      "source": [
        "zBaseDir = env_CONTENT_PATH + \"/mlruns/\"\n",
        "zSubDir = get_most_recent_numeric_subdirectory( zBaseDir )\n",
        "print( \"zSubDir=\"+zSubDir)\n",
        "zSubSubDir = get_most_recent_numeric_subdirectory( zSubDir )\n",
        "loaded_model = pickle.load(open( zSubSubDir + \"/artifacts/Bat_guts_IVP_classifier/model.pkl\", 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "uz_8EVEl0O14",
        "outputId": "455260a4-bf9a-4ab4-8d76-35542c6b6e53"
      },
      "outputs": [],
      "source": [
        "zBase= env_CONTENT_PATH + '/images/Bats_mixed_images_RGB_256/Plants'\n",
        "zFilePath = zBase + \"/DRXXX_Brachyphylla_pumila-LY20_13-nectar-guts-LY20-13A-HE-006-Plane004__red.jpeg\"\n",
        "classify(zFilePath,loaded_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "MNj_VDDZ29OT",
        "outputId": "9a74c720-e917-41b9-8276-d70726f1a4db"
      },
      "outputs": [],
      "source": [
        "zBase= env_CONTENT_PATH + '/images/Bats_mixed_images_RGB_256/Plants'\n",
        "zFilePath = zBase + \"/DRXXX_Brachyphylla_pumila-LY20_13-nectar-guts-LY20-13A-HE-006-Plane005__blue.jpeg\"\n",
        "classify(zFilePath,loaded_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2Lrbs7c29WX"
      },
      "outputs": [],
      "source": [
        "paths = glob.glob(os.path.join(env_CONTENT_PATH + \"/images/Bats_mixed_images_RGB_256/\"+ str('Plants')+\"/\",\"*.jpeg\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roFhjGYOZzDa"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "rrQ5ewYKZ0v1",
        "outputId": "de64e7ca-7ea0-4204-c2c1-55ac5bba6dcc"
      },
      "outputs": [],
      "source": [
        "zBaseDir = env_CONTENT_PATH + \"/mlruns/\"\n",
        "zSubDir = get_most_recent_numeric_subdirectory( zBaseDir )\n",
        "print( \"zSubDir=\"+zSubDir)\n",
        "zSubSubDir = get_most_recent_numeric_subdirectory( zSubDir )\n",
        "loaded_model = pickle.load(open( zSubSubDir + \"/artifacts/Bat_guts_IVP_classifier/model.pkl\", 'rb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s79tJj_EZ02C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUENsd21Anw-",
        "outputId": "75f695c3-bac8-4d20-ce43-bfbc26c4fe0a"
      },
      "outputs": [],
      "source": [
        "len(paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYNMIU2b2MOG"
      },
      "outputs": [],
      "source": [
        "k=0\n",
        "for path in paths:\n",
        "\n",
        "  if 'Bat eats Insects' == classify(path,loaded_model):\n",
        "    print('here')\n",
        "    k=k+1\n",
        "  else:\n",
        "    print(path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCY8HuzrAlKE",
        "outputId": "91c0da31-2f26-44ed-aaa2-c25b0e3e1af2"
      },
      "outputs": [],
      "source": [
        "k,len(paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwBi2-RzC0xF"
      },
      "outputs": [],
      "source": [
        "j=0\n",
        "for path in paths:\n",
        "\n",
        "  if 'Bat eats Plants' == classify(path,loaded_model):\n",
        "    print('here')\n",
        "    j=j+1\n",
        "  else:\n",
        "    print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWDHw5LYDCo_",
        "outputId": "7537ba20-b44b-4e41-9010-fe8e255d9fc2"
      },
      "outputs": [],
      "source": [
        "j,len(paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "eO8kE2Iwod12",
        "outputId": "aaa01167-5fa2-4857-feca-cd7cede7027e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGMcEKYB4Dyo"
      },
      "outputs": [],
      "source": [
        "#check versions\n",
        "import flask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-GFz1p44GyQ",
        "outputId": "2138cd3e-ee8f-4bee-9c13-7a8c9469c196"
      },
      "outputs": [],
      "source": [
        "print(flask.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSln8t4S4JLL",
        "outputId": "28256868-5252-441d-d4bf-3cda66657ef4"
      },
      "outputs": [],
      "source": [
        "print(np.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FODyyjqB4Rrb",
        "outputId": "73ea5a2b-6bdb-4a77-8220-fa4e6b0f013b"
      },
      "outputs": [],
      "source": [
        "!python3 --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7P2uETRRD8X"
      },
      "outputs": [],
      "source": [
        "import mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rq6hgmTG6JB",
        "outputId": "0f2232c3-16bf-4654-8212-a62de17f8fa3"
      },
      "outputs": [],
      "source": [
        "print(mlflow.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbPRa35CRCj-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
